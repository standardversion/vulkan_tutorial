#define STB_IMAGE_IMPLEMENTATION
#define GLFW_INCLUDE_VULKAN
#define GLM_FORCE_RADIANS
#define GLM_FORCE_DEFAULT_ALIGNED_GENTYPES
/*
The perspective projection matrix generated by GLM will use the OpenGL
depth range of -1.0 to 1.0 by default. We need to configure it to use the Vulkan
range of 0.0 to 1.0 using the GLM_FORCE_DEPTH_ZERO_TO_ONE definition
*/
#define GLM_FORCE_DEPTH_ZERO_TO_ONE
#include <GLFW/glfw3.h>
#include <glm/glm.hpp>
#include <glm/gtc/matrix_transform.hpp>
#include <stb_image.h>

#include <chrono>
#include <iostream>
#include <stdexcept>
#include <cstdlib>
#include <vector>
#include <optional>
#include <set>
#include <cstdint>
#include <limits>
#include <algorithm>
#include <fstream>
#include <array>

const uint32_t WIDTH{ 800 };
const uint32_t HEIGHT{ 600 };
/*
We choose the number 2 because we don’t want the CPU to get too far ahead
of the GPU. With 2 frames in flight, the CPU and the GPU can be working
on their own tasks at the same time. If the CPU finishes early, it will wait
till the GPU finishes rendering before submitting more work. With 3 or more
frames in flight, the CPU could get ahead of the GPU, adding frames of latency.
Generally, extra latency isn’t desired.
*/
const int MAX_FRAMES_IN_FLIGHT{ 2 };
//All of the useful standard validation is bundled into
//a layer included in the SDK that is known as VK_LAYER_KHRONOS_validation.
const std::vector<const char*> validationLayers{ "VK_LAYER_KHRONOS_validation" };
const std::vector<const char*> deviceExtensions{ VK_KHR_SWAPCHAIN_EXTENSION_NAME };

struct UniformBufferObject
{
	/*
	The data in the matrices is binary compatible with the way the shader expects
	it, so we can later just memcpy a UniformBufferObject to a VkBuffer.

	Vulkan expects the data in your structure to be aligned in memory in a specific
	way, for example:
	• Scalars have to be aligned by N (= 4 bytes given 32 bit floats).
	• A vec2 must be aligned by 2N (= 8 bytes)
	• A vec3 or vec4 must be aligned by 4N (= 16 bytes)
	• A nested structure must be aligned by the base alignment of its members
	rounded up to a multiple of 16.
	• A mat4 matrix must have the same alignment as a vec4.
	You can find the full list of alignment requirements in the specification.
	*/
	alignas(16) glm::mat4 model;
	alignas(16) glm::mat4 view;
	alignas(16) glm::mat4 proj;
};

struct Vertex
{
	glm::vec3 pos;
	glm::vec3 color;
	glm::vec2 texCoord;

	static VkVertexInputBindingDescription getBindingDescription()
	{
		/*
		A vertex binding describes at which rate to load data from memory throughout
		the vertices. It specifies the number of bytes between data entries and whether
		to move to the next data entry after each vertex or after each instance.
		*/
		VkVertexInputBindingDescription bindingDescription{};
		/*
		All of our per-vertex data is packed together in one array, so we’re only going
		to have one binding. The binding parameter specifies the index of the binding
		in the array of bindings. The stride parameter specifies the number of bytes
		from one entry to the next, and the inputRate parameter can have one of the
		following values:
		• VK_VERTEX_INPUT_RATE_VERTEX: Move to the next data entry after each
		vertex
		• VK_VERTEX_INPUT_RATE_INSTANCE: Move to the next data entry after
		each instance
		*/
		bindingDescription.binding = 0;
		bindingDescription.stride = sizeof(Vertex);
		bindingDescription.inputRate = VK_VERTEX_INPUT_RATE_VERTEX;
		return bindingDescription;
	}

	static std::array<VkVertexInputAttributeDescription, 3> getAttributeDescription()
	{
		std::array<VkVertexInputAttributeDescription, 3> attributeDescriptions{};
		/*
		The binding parameter tells Vulkan from which binding the per-vertex data
		comes. The location parameter references the location directive of the input
		in the vertex shader. The input in the vertex shader with location 0 is the
		position, which has two 32-bit float components.
		The format parameter describes the type of data for the attribute. A bit confusingly,
		the formats are specified using the same enumeration as color formats.
		The following shader types and formats are commonly used together:
		• float: VK_FORMAT_R32_SFLOAT
		• vec2: VK_FORMAT_R32G32_SFLOAT
		• vec3: VK_FORMAT_R32G32B32_SFLOAT
		• vec4: VK_FORMAT_R32G32B32A32_SFLOAT
		As you can see, you should use the format where the amount of color channels
		matches the number of components in the shader data type. It is allowed to
		use more channels than the number of components in the shader, but they will
		be silently discarded. If the number of channels is lower than the number of
		components, then the BGA components will use default values of (0, 0, 1).
		The color type (SFLOAT, UINT, SINT) and bit width should also match the type
		of the shader input. See the following examples:
		• ivec2: VK_FORMAT_R32G32_SINT, a 2-component vector of 32-bit signed
		integers
		• uvec4: VK_FORMAT_R32G32B32A32_UINT, a 4-component vector of 32-bit
		unsigned integers
		• double: VK_FORMAT_R64_SFLOAT, a double-precision (64-bit) float
		The format parameter implicitly defines the byte size of attribute data and the
		offset parameter specifies the number of bytes since the start of the per-vertex
		data to read from. The binding is loading one Vertex at a time and the position
		attribute (pos) is at an offset of 0 bytes from the beginning
		*/
		attributeDescriptions[0].binding = 0;
		attributeDescriptions[0].location = 0;
		attributeDescriptions[0].format = VK_FORMAT_R32G32B32_SFLOAT;
		attributeDescriptions[0].offset = offsetof(Vertex, pos);

		attributeDescriptions[1].binding = 0;
		attributeDescriptions[1].location = 1;
		attributeDescriptions[1].format = VK_FORMAT_R32G32B32_SFLOAT;
		attributeDescriptions[1].offset = offsetof(Vertex, color);

		attributeDescriptions[2].binding = 0;
		attributeDescriptions[2].location = 2;
		attributeDescriptions[2].format = VK_FORMAT_R32G32_SFLOAT;
		attributeDescriptions[2].offset = offsetof(Vertex, texCoord);
		return attributeDescriptions;
	}
};

std::vector<Vertex> vertices{
	{{-0.5f, -0.5f, 0.0f}, {1.0f, 0.0f, 0.0f}, {1.0f, 0.0f}},
	{{0.5f, -0.5f, 0.0f}, {0.0f, 1.0f, 0.0f}, {0.0f, 0.0f}},
	{{0.5f, 0.5f, 0.0f}, {0.0f, 0.0f, 1.0f}, {0.0f, 1.0f}},
	{{-0.5f, 0.5f, 0.0f}, {1.0f, 1.0f, 1.0f}, {1.0f, 1.0f}},

	{{-0.5f, -0.5f, -0.5f}, {1.0f, 0.0f, 0.0f}, {1.0f, 0.0f}},
	{{0.5f, -0.5f, -0.5f}, {0.0f, 1.0f, 0.0f}, {0.0f, 0.0f}},
	{{0.5f, 0.5f, -0.5f}, {0.0f, 0.0f, 1.0f}, {0.0f, 1.0f}},
	{{-0.5f, 0.5f, -0.5f}, {1.0f, 1.0f, 1.0f}, {1.0f, 1.0f}}
};

/*
Indices to represent the contents of the index buffer.
It should match the indices to draw the
upper-right triangle and bottom-left triangle.
(vertex indices)
It is possible to use either uint16_t or uint32_t for your index buffer depending
on the number of entries in vertices. We can stick to uint16_t for now because
we’re using less than 65535 unique vertices.
*/
const std::vector<uint16_t> indices{ 
	0, 1, 2, 2, 3, 0, 
	4, 5, 6, 6, 7, 4
};

#ifdef NDEBUG
	const bool enableValidationLayers{ false };
#else
	const bool enableValidationLayers{ true };
#endif // NDEBUG

//vkCreateDebugUtilsMessengerEXT is an extension function it is not automatically loaded
//we've to get the address to the function using vkGetInstanceProcAddr
VkResult CreateDebugUtilsMessengerEXT(
	VkInstance instance,
	const VkDebugUtilsMessengerCreateInfoEXT* pCreateInfo,
	const VkAllocationCallbacks* pAllocator,
	VkDebugUtilsMessengerEXT* pDebugMessenger
)
{
	//casting the result of vkGetInstanceProcAddr to this specific function pointer type
	auto func = (PFN_vkCreateDebugUtilsMessengerEXT) // pointer to function
		vkGetInstanceProcAddr(instance, "vkCreateDebugUtilsMessengerEXT");
	if (func != nullptr)
	{
		return func(instance, pCreateInfo, pAllocator, pDebugMessenger);
	}
	else
	{
		return VK_ERROR_EXTENSION_NOT_PRESENT;
	}
}

//vkDestroyDebugUtilsMessengerEXT is an extension function it is not automatically loaded
//we've to get the address to the function using vkGetInstanceProcAddr
void DestroyDebugUtilsMessengerEXT(
	VkInstance instance,
	VkDebugUtilsMessengerEXT debugMessenger,
	const VkAllocationCallbacks* pAllocator
)
{
	//casting the result of vkGetInstanceProcAddr to this specific function pointer type
	auto func = (PFN_vkDestroyDebugUtilsMessengerEXT) // pointer to function
		vkGetInstanceProcAddr(instance, "vkDestroyDebugUtilsMessengerEXT");
	if (func != nullptr)
	{
		func(instance, debugMessenger, pAllocator);
	}
}

struct QueueFamilyIndices
{
	std::optional<uint32_t> grahicsFamily;
	/*
	* presentation is a queue-specific feature
	It’s actually possible that the queue families supporting drawing commands and
	the ones supporting presentation do not overlap. Therefore we have to take into
	account that there could be a distinct presentation queue
	*/
	std::optional<uint32_t> presentFamily;

	bool isComplete()
	{
		return grahicsFamily.has_value() && presentFamily.has_value();
	}
};

struct SwapChainSupportDetails
{
	VkSurfaceCapabilitiesKHR capabilities;
	std::vector<VkSurfaceFormatKHR> formats;
	std::vector<VkPresentModeKHR> presentModes;
};


class HelloTriangleApplication
{
public:
	void run()
	{
		initWindow();
		initVulkan();
		mainLoop();
		cleanup();
	}

private:
	GLFWwindow* window;
	VkInstance instance;
	VkDebugUtilsMessengerEXT debugMessenger;
	VkSurfaceKHR surface;
	VkPhysicalDevice physicalDevice{ VK_NULL_HANDLE };
	VkDevice device;
	VkQueue graphicsQueue;
	VkQueue presentQueue;
	VkSwapchainKHR swapChain;
	std::vector<VkImage> swapChainImages;
	VkFormat swapChainImageFormat;
	VkExtent2D swapChainExtent;
	std::vector<VkImageView> swapChainImageViews;
	VkRenderPass renderPass;
	VkDescriptorSetLayout descriptorSetLayout;
	VkDescriptorPool descriptorPool;
	std::vector<VkDescriptorSet> descriptorSets;
	VkPipelineLayout pipelineLayout;
	VkPipeline graphicsPipeline;
	std::vector<VkFramebuffer> swapChainFramebuffers;
	VkCommandPool commandPool;
	VkBuffer vertexBuffer;
	VkDeviceMemory vertexBufferMemory;
	VkBuffer indexBuffer;
	VkDeviceMemory indexBufferMemory;
	std::vector<VkBuffer> uniformBuffers;
	std::vector<VkDeviceMemory> uniformBuffersMemory;
	std::vector<void*> uniformBuffersMapped;
	std::vector<VkCommandBuffer> commandBuffers;
	std::vector<VkSemaphore> imageAvailableSemaphores;
	std::vector<VkSemaphore> renderFinishedSemaphores;
	std::vector<VkFence> inFlightFences;
	bool framebufferResized{ false };
	uint32_t currentFrame{ 0 };
	VkImage textureImage;
	VkDeviceMemory textureImageMemory;
	VkImageView textureImageView;
	VkSampler textureSampler;
	VkImage depthImage;
	VkDeviceMemory depthImageMemory;
	VkImageView depthImageView;

	void initWindow()
	{
		glfwInit();

		glfwWindowHint(GLFW_CLIENT_API, GLFW_NO_API); // we don't want to create a opengl context
		//glfwWindowHint(GLFW_RESIZABLE, GLFW_FALSE); // window resizing is more involved so disable it

		window = glfwCreateWindow(WIDTH, HEIGHT, "Vulkan", nullptr, nullptr); // 1st nullptr is for monitor, 2nd for opengl
		glfwSetWindowUserPointer(window, this);
		glfwSetFramebufferSizeCallback(window, framebufferResizeCallback);

	}

	void initVulkan()
	{
		/*
		The very first thing you need to do is initialize the Vulkan library by creating
		an instance. The instance is the connection between your application and
		the Vulkan library and creating it involves specifying some details about your
		application to the driver.
		*/
		createInstance();
		/*
		Setting up the debug messenger function requires the instance to be created first
		Since vkCreateDebugUtilsMessengerEXT func is an extension func the instance is required
		to retrieve it's function pointer. Debug Messenger will handle output of validation layers
		*/
		setupDebugMessenger();
		/*
		The window surface needs to be created right after the instance creation, because
		it can actually influence the physical device selection.
		Window surfaces are an entirely optional component in Vulkan, if you just need off-screen rendering.
		*/
		createSurface();
		/*
		After initializing the Vulkan library through a VkInstance we need to look for
		and select a graphics card in the system that supports the features we need
		*/
		pickPhysicalDevice();
		/*
		Create a logical device to interface with the physical device.
		The logical device creation process is similar to the instance
		creation process and describes the features we want to use. We also need to
		specify which queues to create now that we’ve queried which queue families are
		available. You can even create multiple logical devices from the same physical
		device if you have varying requirements.
		*/
		createLogicalDevice();
		/*
		With the logical device and queue handles we can now actually start using the
		graphics card to do things!
		Make sure to call createSwapChain after logical device creation.
		*/
		createSwapChain();
		/*
		To use any VkImage, including those in the swap chain, in the render pipeline
		we have to create a VkImageView object. An image view is quite literally a
		view into an image. It describes how to access the image and which part of
		the image to access, for example if it should be treated as a 2D texture depth
		texture without any mipmapping levels.
		*/
		createImageViews();
		/*
		Before we can finish creating the pipeline, we need to tell Vulkan about the
		framebuffer attachments that will be used while rendering. We need to specify
		how many color and depth buffers there will be, how many samples to use
		for each of them and how their contents should be handled throughout the
		rendering operations. All of this information is wrapped in a render pass object,
		for which we’ll create a new createRenderPass function.
		*/
		createRenderPass();
		/*
		We need to provide details about every descriptor binding used in the shaders
		for pipeline creation, just like we had to do for every vertex attribute and its
		location index.
		*/
		createDescriptorSetLayout();
		/*
		The graphics pipeline is the sequence
		of operations that take the vertices and textures of your meshes all the
		way to the pixels in the render targets.
		*/
		createGraphicsPipeline();
		/*
		Commands in Vulkan, like drawing operations and memory transfers, are not
		executed directly using function calls. You have to record all of the operations
		you want to perform in command buffer objects. The advantage of this is
		that when we are ready to tell the Vulkan what we want to do, all of the
		commands are submitted together and Vulkan can more efficiently process the
		commands since all of them are available together. In addition, this allows
		command recording to happen in multiple threads if so desired.

		We have to create a command pool before we can create command buffers.
		Command pools manage the memory that is used to store the buffers and command
		buffers are allocated from them.
		*/
		createCommandPool();
		createDepthResources();
		/*
		The attachments specified during render pass creation are bound by wrapping
		them into a VkFramebuffer object. A framebuffer object references all of the
		VkImageView objects that represent the attachments. In our case that will be
		only a single one: the color attachment. However, the image that we have to
		use for the attachment depends on which image the swap chain returns when we
		retrieve one for presentation. That means that we have to create a framebuffer
		for all of the images in the swap chain and use the one that corresponds to the
		retrieved image at drawing time.
		*/
		createFramebuffers();
		/*
		Adding a texture to our application will involve the following steps:
		• Create an image object backed by device memory
		• Fill it with pixels from an image file
		• Create an image sampler
		• Add a combined image sampler descriptor to sample colors from the texture
		*/
		createTextureImage();
		/*
		with the swap chain images and the framebuffer, that images
		are accessed through image views rather than directly. We will also need to
		create such an image view for the texture image.
		*/
		createTextureImageView();
		/*
		It is possible for shaders to read texels directly from images, but that is not very
		common when they are used as textures. Textures are usually accessed through
		samplers, which will apply filtering and transformations to compute the final
		color that is retrieved.
		*/
		createTextureSampler();
		/*
		Buffers in Vulkan are regions of memory used for storing arbitrary data that can
		be read by the graphics card. They can be used to store vertex data but they can
		also be used for many other purposes. Unlike the Vulkan objects buffers do not
		automatically allocate memory for themselves.
		*/
		createVertexBuffer();
		/*
		Drawing a rectangle takes two triangles, which means that we need a vertex
		buffer with 6 vertices. The problem is that the data of two vertices needs to be
		duplicated resulting in 50% redundancy. It only gets worse with more complex
		meshes, where vertices are reused in an average number of 3 triangles. The
		solution to this problem is to use an index buffer.
		An index buffer is essentially an array of pointers into the vertex buffer. It allows
		you to reorder the vertex data, and reuse existing data for multiple vertices.
		*/
		createIndexBuffer();
		/*
		A descriptor is a way for shaders to freely access resources like buffers and images. We’re
		going to set up a buffer that contains the transformation matrices and have the
		vertex shader access them through a descriptor. Usage of descriptors consists
		of three parts:
		• Specify a descriptor layout during pipeline creation
		• Allocate a descriptor set from a descriptor pool
		• Bind the descriptor set during rendering
		The descriptor layout specifies the types of resources that are going to be accessed
		by the pipeline, just like a render pass specifies the types of attachments
		that will be accessed. A descriptor set specifies the actual buffer or image resources
		that will be bound to the descriptors, just like a framebuffer specifies
		the actual image views to bind to render pass attachments. The descriptor
		set is then bound for the drawing commands just like the vertex buffers and
		framebuffer.
		*/
		createUniformBuffers();
		/*
		Descriptor sets can’t be created directly, they must be allocated from a pool like
		command buffers. The equivalent for descriptor sets is unsurprisingly called a
		descriptor pool.
		*/
		createDescriptorPool();
		createDescriptorSets();
		/*
		Commands in Vulkan, like drawing operations and memory transfers, are not
		executed directly using function calls. You have to record all of the operations
		you want to perform in command buffer objects. The advantage of this is
		that when we are ready to tell the Vulkan what we want to do, all of the
		commands are submitted together and Vulkan can more efficiently process the
		commands since all of them are available together. In addition, this allows
		command recording to happen in multiple threads if so desired.
		*/
		createCommandBuffers();

		createSyncObjects();
	}

	void mainLoop()
	{
		while (!glfwWindowShouldClose(window))
		{
			glfwPollEvents();
			drawFrame();
		}

		vkDeviceWaitIdle(device);
	}

	void cleanup()
	{
		cleanupSwapChain();
		vkDestroySampler(device, textureSampler, nullptr);
		vkDestroyImageView(device, textureImageView, nullptr);
		vkDestroyImage(device, textureImage, nullptr);
		vkFreeMemory(device, textureImageMemory, nullptr);
		//The uniform data will be used for all draw calls, so the buffer containing it
		//should only be destroyed when we stop rendering.
		for (size_t i{ 0 }; i < MAX_FRAMES_IN_FLIGHT; i++)
		{
			vkDestroyBuffer(device, uniformBuffers[i], nullptr);
			vkFreeMemory(device, uniformBuffersMemory[i], nullptr);
		}
		vkDestroyDescriptorSetLayout(device, descriptorSetLayout, nullptr);
		vkDestroyBuffer(device, vertexBuffer, nullptr);
		vkFreeMemory(device, vertexBufferMemory, nullptr);
		vkDestroyBuffer(device, indexBuffer, nullptr);
		vkFreeMemory(device, indexBufferMemory, nullptr);
		vkDestroyPipeline(device, graphicsPipeline, nullptr);
		vkDestroyPipelineLayout(device, pipelineLayout, nullptr);

		vkDestroyRenderPass(device, renderPass, nullptr);

		for (size_t i{ 0 }; i < MAX_FRAMES_IN_FLIGHT; i++)
		{
			vkDestroySemaphore(device, imageAvailableSemaphores[i], nullptr);
			vkDestroySemaphore(device, renderFinishedSemaphores[i], nullptr);
			vkDestroyFence(device, inFlightFences[i], nullptr);
		}

		vkDestroyCommandPool(device, commandPool, nullptr);
		
		//Logical devices don’t interact directly with instances, which is why it’s not included as a parameter.
		vkDestroyDevice(device, nullptr);
		if (enableValidationLayers)
		{
			//The VkDebugUtilsMessengerEXT object also needs to be cleaned up with a call
			//to vkDestroyDebugUtilsMessengerEXT.Similarly to vkCreateDebugUtilsMessengerEXT
			//the function needs to be explicitly loaded.
			DestroyDebugUtilsMessengerEXT(instance, debugMessenger, nullptr);
		}
		//GLFW doesn’t offer a special function for destroying a surface, 
		//but that can easily be done through the original API
		//Make sure that the surface is destroyed before the instance.
		vkDestroySurfaceKHR(instance, surface, nullptr);
		//The VkInstance should be only destroyed right before the program exits.
		vkDestroyInstance(instance, nullptr);
		//Once the window is closed, we need to clean up resources by destroying it and terminating GLFW itself
		glfwDestroyWindow(window);
		glfwTerminate();
	}

	void cleanupSwapChain()
	{
		vkDestroyImageView(device, depthImageView, nullptr);
		vkDestroyImage(device, depthImage, nullptr);
		vkFreeMemory(device, depthImageMemory, nullptr);
		//delete the framebuffers before the image views and render pass that
		//they are based on, but only after we’ve finished rendering
		for (auto framebuffer : swapChainFramebuffers)
		{
			vkDestroyFramebuffer(device, framebuffer, nullptr);
		}
		for (auto imageView : swapChainImageViews)
		{
			vkDestroyImageView(device, imageView, nullptr);
		}
		//Destroy swap chain
		vkDestroySwapchainKHR(device, swapChain, nullptr);
	}

	void createInstance()
	{
		/*
		The instance is the connection between your application and
		the Vulkan library and creating it involves specifying some details about your
		application to the driver.
		*/
		VkApplicationInfo appInfo{};
		appInfo.sType = VK_STRUCTURE_TYPE_APPLICATION_INFO;
		appInfo.pApplicationName = "Hello Triangle";
		appInfo.applicationVersion = VK_MAKE_VERSION(1, 0, 0);
		appInfo.pEngineName = "No Engine";
		appInfo.engineVersion = VK_MAKE_VERSION(1, 0, 0);
		appInfo.apiVersion = VK_API_VERSION_1_0;

		/*
		This next struct is not optional and tells
		the Vulkan driver which global extensions and validation layers we want to use.
		Global here means that they apply to the entire program and not a specific device
		*/
		VkInstanceCreateInfo createInfo{};
		createInfo.sType = VK_STRUCTURE_TYPE_INSTANCE_CREATE_INFO;
		createInfo.pApplicationInfo = &appInfo;
		/*
		Vulkan is a platform agnostic API, which means that you need an extension to interface
		with the window system. GLFW has a handy built-in function that returns the
		extension(s) it needs to do that which we can pass to the struct
		*/
		std::vector<const char*> requiredExtensions{ getRequiredExtensions() };
		createInfo.enabledExtensionCount = requiredExtensions.size();
		createInfo.ppEnabledExtensionNames = requiredExtensions.data();
		createInfo.enabledLayerCount = 0;

		/*
		To retrieve a list of supported extensions before creating an instance,
		there’s the vkEnumerateInstanceExtensionProperties function.
		*/
		uint32_t extenstionCount{ 0 };
		//first arg is to filter, last arg is to store
		vkEnumerateInstanceExtensionProperties(nullptr, &extenstionCount, nullptr);
		std::vector<VkExtensionProperties> extensionProperties(extenstionCount);
		//extensions.data() gives you a VkExtensionProperties*
		vkEnumerateInstanceExtensionProperties(nullptr, &extenstionCount, extensionProperties.data());

		if (!checkExtenstionSupport(requiredExtensions, extensionProperties))
		{
			throw std::runtime_error("all required glfw extensions not supported!");
		}
		
		/*
		The Vulkan API is designed around the idea of minimal driver overhead and one
		of the manifestations of that goal is that there is very limited error checking in
		the API by default. Even mistakes as simple as setting enumerations to incorrect
		values or passing null pointers to required parameters are generally not explicitly
		handled and will simply result in crashes or undefined behavior. Because Vulkan
		requires you to be very explicit about everything you’re doing, it’s easy to make
		many small mistakes like using a new GPU feature and forgetting to request it
		at logical device creation time.
		However, that doesn’t mean that these checks can’t be added to the API. Vulkan
		introduces an elegant system for this known as validation layers. Validation
		layers are optional components that hook into Vulkan function calls to apply
		additional operations. Common operations in validation layers are:
		• Checking the values of parameters against the specification to detect misuse
		• Tracking creation and destruction of objects to find resource leaks
		• Checking thread safety by tracking the threads that calls originate from
		• Logging every call and its parameters to the standard output
		• Tracing Vulkan calls for profiling and replaying
		*/
		// check validation layer support
		// The debugCreateInfo variable is placed outside the if statement to ensure
		// that it is not destroyed before the vkCreateInstance call.
		VkDebugUtilsMessengerCreateInfoEXT debugCreateInfo;
		if (enableValidationLayers)
		{
			uint32_t layerCount{ 0 };
			vkEnumerateInstanceLayerProperties(&layerCount, nullptr);
			std::vector<VkLayerProperties> availableLayers(layerCount);
			vkEnumerateInstanceLayerProperties(&layerCount, availableLayers.data());

			if (!checkValidationLayerSupport(availableLayers))
			{
				throw std::runtime_error("all required validation layers not supported");
			}
			createInfo.enabledLayerCount = validationLayers.size();
			createInfo.ppEnabledLayerNames = validationLayers.data();

			populateDebugMessengerCreateInfo(debugCreateInfo);
			createInfo.pNext = (VkDebugUtilsMessengerCreateInfoEXT*)&debugCreateInfo;
		}
		else
		{
			createInfo.enabledLayerCount = 0;
			createInfo.pNext = nullptr;
		}

		if (vkCreateInstance(&createInfo, nullptr, &instance) != VK_SUCCESS)
		{
			throw std::runtime_error("failed to create instance!");
		}
	}

	std::vector<const char*> getRequiredExtensions()
	{
		//Vulkan is a platform agnostic API, which means that you need an extension to interface
		//with the window system. GLFW has a handy built-in function that returns the extension(s) it needs

		uint32_t glfwExtensionCount{ 0 };
		const char** glfwExtensions{ glfwGetRequiredInstanceExtensions(&glfwExtensionCount) };
		std::vector<const char*> extensions(glfwExtensions, glfwExtensions + glfwExtensionCount);

		if (enableValidationLayers)
		{
			//To set up a callback in the program to handle messages and the associated
			//details, we have to set up a debug messenger with a callback using the
			//VK_EXT_debug_utils extension. VK_EXT_debug_utils = VK_EXT_DEBUG_UTILS_EXTENSION_NAME
			extensions.push_back(VK_EXT_DEBUG_UTILS_EXTENSION_NAME);
		}
		return extensions;
	}

	bool checkExtenstionSupport(std::vector<const char*> requiredExtensions, const std::vector<VkExtensionProperties>& vkExtensionProperties)
	{
		for (const auto& requiredExt: requiredExtensions)
		{
			bool found{ false };

			for (const auto& extensionProperty : vkExtensionProperties)
			{
				if (strcmp(extensionProperty.extensionName, requiredExt) == 0)
				{
					found = true;
					break;
				}
			}
			if (!found)
			{
				std::cerr << "Missing GLFW extension: " << requiredExt << std::endl;
				return false;
			}
		}
		return true;
	}

	bool checkValidationLayerSupport(const std::vector<VkLayerProperties>& availableLayers)
	{
		for (const auto& layer : validationLayers)
		{
			bool found{ false };

			for (const auto& availableLayer : availableLayers)
			{
				if (strcmp(layer, availableLayer.layerName) == 0)
				{
					found = true;
					break;
				}
			}
			if (!found)
			{
				std::cerr << "Missing validation layer: " << layer << std::endl;
				return false;
			}
		}
		return true;
	}

	void populateDebugMessengerCreateInfo(VkDebugUtilsMessengerCreateInfoEXT& createInfo)
	{
		createInfo = {};
		createInfo.sType = VK_STRUCTURE_TYPE_DEBUG_UTILS_MESSENGER_CREATE_INFO_EXT;
		//The messageSeverity field allows you to specify all the types of severities
		//you would like your callback to be called for.
		createInfo.messageSeverity =
			//Diagnostic message
			VK_DEBUG_UTILS_MESSAGE_SEVERITY_VERBOSE_BIT_EXT |
			//Message about behavior that is not necessarily an error, but very likely a bug in your application
			VK_DEBUG_UTILS_MESSAGE_SEVERITY_WARNING_BIT_EXT |
			//Message about behavior that is invalid and may cause crashes
			VK_DEBUG_UTILS_MESSAGE_SEVERITY_ERROR_BIT_EXT;
		// messageType field lets you filter which types of messages your callback is notified about.
		createInfo.messageType =
			//Some event has happened that is unrelated to the specification or performance
			VK_DEBUG_UTILS_MESSAGE_TYPE_GENERAL_BIT_EXT |
			//Something has happened that violates the specification or indicates a possible mistake
			VK_DEBUG_UTILS_MESSAGE_TYPE_VALIDATION_BIT_EXT |
			//Potential nonoptimal use of Vulkan
			VK_DEBUG_UTILS_MESSAGE_TYPE_PERFORMANCE_BIT_EXT;
		/*
		The validation layers will print debug messages to the standard output by default,
		but we can also handle them ourselves by providing an explicit callback
		in our program. This will also allow you to decide which kind of messages you
		would like to see, because not all are necessarily (fatal) errors.
		*/
		createInfo.pfnUserCallback = debugCallback;
	}

	void setupDebugMessenger()
	{
		if (!enableValidationLayers) return;
		VkDebugUtilsMessengerCreateInfoEXT createInfo;
		populateDebugMessengerCreateInfo(createInfo);

		if (CreateDebugUtilsMessengerEXT(instance, &createInfo, nullptr, &debugMessenger) != VK_SUCCESS)
		{
			throw std::runtime_error("failed to setup debug messenger!");
		}
	}

	void createSurface()
	{
		if (glfwCreateWindowSurface(instance, window, nullptr, &surface) != VK_SUCCESS)
		{
			throw std::runtime_error("failed to create window surface!");
		}
	}

	void pickPhysicalDevice()
	{
		uint32_t deviceCount{ 0 };
		vkEnumeratePhysicalDevices(instance, &deviceCount, nullptr);
		if (deviceCount == 0)
		{
			throw std::runtime_error("failed to find GPUs with Vulkan support!");
		}
		std::vector<VkPhysicalDevice> devices(deviceCount);
		vkEnumeratePhysicalDevices(instance, &deviceCount, devices.data());

		/*
		we need to evaluate each of them and check if they are suitable for the
		operations we want to perform, because not all graphics cards are created equal.
		*/
		for (const auto& device : devices)
		{
			if (isDeviceSuitable(device))
			{
				physicalDevice = device;
				break;
			}
		}
		if (physicalDevice == VK_NULL_HANDLE)
		{
			throw std::runtime_error("failed to find suitable GPU!");
		}
	}

	bool isDeviceSuitable(VkPhysicalDevice device)
	{
		/*
		Almost every operation in Vulkan, anything from drawing to uploading textures, requires commands to be submitted
		to a queue. There are different types of queues that originate from different
		queue families and each family of queues allows only a subset of commands.
		*/
		QueueFamilyIndices indices{ findQueueFamilies(device) };
		bool extensionsSupported{ checkDeviceExtensionSupport(device) };
		bool swapChainAdequate{ false };
		if (extensionsSupported)
		{
			/*
			Vulkan does not have the concept of a “default framebuffer”, hence it requires
			an infrastructure that will own the buffers we will render to before we visualize
			them on the screen. This infrastructure is known as the swap chain and must
			be created explicitly in Vulkan. The swap chain is essentially a queue of images
			that are waiting to be presented to the screen. Our application will acquire
			such an image to draw to it, and then return it to the queue. How exactly the
			queue works and the conditions for presenting an image from the queue depend
			on how the swap chain is set up, but the general purpose of the swap chain is
			to synchronize the presentation of images with the refresh rate of the screen.
			*/
			SwapChainSupportDetails swapChainSupport{ querySwapChainSupport(device) };
			swapChainAdequate = !swapChainSupport.formats.empty() && !swapChainSupport.presentModes.empty();
		}
		VkPhysicalDeviceFeatures supportedFeatures;
		vkGetPhysicalDeviceFeatures(device, &supportedFeatures);

		return indices.isComplete() && extensionsSupported && swapChainAdequate && supportedFeatures.samplerAnisotropy;
	}

	QueueFamilyIndices findQueueFamilies(VkPhysicalDevice device)
	{
		QueueFamilyIndices indices;
		uint32_t queueFamilyCount{ 0 };
		vkGetPhysicalDeviceQueueFamilyProperties(device, &queueFamilyCount, nullptr);
		/*
		The VkQueueFamilyProperties struct contains some details about the queue
		family, including the type of operations that are supported and the number of
		queues that can be created based on that family.
		*/
		std::vector<VkQueueFamilyProperties> queueFamilies(queueFamilyCount);
		vkGetPhysicalDeviceQueueFamilyProperties(device, &queueFamilyCount, queueFamilies.data());

		int i{ 0 };
		for (const auto& queueFamily : queueFamilies)
		{
			//We need to find at least one queue family that supports VK_QUEUE_GRAPHICS_BIT.
			if (queueFamily.queueFlags & VK_QUEUE_GRAPHICS_BIT)
			{
				indices.grahicsFamily = i;
			}
			/*
			Although the Vulkan implementation may support window system integration,
			that does not mean that every device in the system supports it. we to ensure that
			a device can present images to the surface we created. 
			Since the presentation is a queue-specific feature, the
			problem is actually about finding a queue family that supports presenting to
			the surface we created.
			*/
			VkBool32 presentSupport{ false };
			vkGetPhysicalDeviceSurfaceSupportKHR(device, i, surface, &presentSupport);
			if (presentSupport)
			{
				indices.presentFamily = i;
			}
			if (indices.isComplete())
			{
				break;
			}
			i++;
		}
		return indices;
	}

	bool checkDeviceExtensionSupport(VkPhysicalDevice device)
	{
		/*
		Not all graphics cards are capable of presenting images directly to a screen for
		various reasons, for example because they are designed for servers and don’t
		have any display outputs. Secondly, since image presentation is heavily tied
		into the window system and the surfaces associated with windows, it is not
		actually part of the Vulkan core. You have to enable the VK_KHR_swapchain
		device extension after querying for its support.
		*/
		uint32_t extensionsCount{ 0 };
		vkEnumerateDeviceExtensionProperties(device, nullptr, &extensionsCount, nullptr);
		std::vector<VkExtensionProperties> availableExtensions(extensionsCount);
		vkEnumerateDeviceExtensionProperties(device, nullptr, &extensionsCount, availableExtensions.data());
		for (const auto& extension : deviceExtensions)
		{
			bool found{ false };

			for (const auto& availableExtension : availableExtensions)
			{
				if (strcmp(extension, availableExtension.extensionName) == 0)
				{
					found = true;
					break;
				}
			}
			if (!found)
			{
				std::cerr << "Missing device extension: " << extension << std::endl;
				return false;
			}
		}
		return true;
	}

	SwapChainSupportDetails querySwapChainSupport(VkPhysicalDevice device)
	{
		/*
		Just checking if a swap chain is available is not sufficient, because it may not
		actually be compatible with our window surface. Creating a swap chain also
		involves a lot more settings than instance and device creation, so we need to
		query for some more details before we’re able to proceed.
		There are basically three kinds of properties we need to check:
		• Basic surface capabilities (min/max number of images in swap chain, min/-
		max width and height of images)
		• Surface formats (pixel format, color space)
		• Available presentation modes
		*/
		SwapChainSupportDetails details;
		vkGetPhysicalDeviceSurfaceCapabilitiesKHR(device, surface, &details.capabilities);
		uint32_t formatCount{ 0 };
		vkGetPhysicalDeviceSurfaceFormatsKHR(device, surface, &formatCount, nullptr);
		if (formatCount != 0)
		{
			details.formats.resize(formatCount);
			vkGetPhysicalDeviceSurfaceFormatsKHR(device, surface, &formatCount, details.formats.data());
		}
		uint32_t presentModeCount{ 0 };
		vkGetPhysicalDeviceSurfacePresentModesKHR(device, surface, &presentModeCount, nullptr);
		if (presentModeCount != 0)
		{
			details.presentModes.resize(presentModeCount);
			vkGetPhysicalDeviceSurfacePresentModesKHR(device, surface, &presentModeCount, details.presentModes.data());
		}
		return details;
	}

	void createLogicalDevice()
	{
		/*
		When creating the logical device, you need to create one or more queues.
		If graphics and presentation are supported by the same queue family, you only need to create one queue.
		But if they’re in different families, you need one for each.
		*/
		QueueFamilyIndices indices{ findQueueFamilies(physicalDevice) };

		//This structure describes the number of queues we want for a single queue family.
		std::vector<VkDeviceQueueCreateInfo> queueCreateInfos;
		std::set<uint32_t> uniqueQueueFamilies{ {
				indices.grahicsFamily.value(),
				indices.presentFamily.value()
		} };
		/*
		The currently available drivers will only allow you to create a small number of
		queues for each queue family and you don’t really need more than one. That’s
		because you can create all of the command buffers on multiple threads and then
		submit them all at once on the main thread with a single low-overhead call.
		Vulkan lets you assign priorities to queues to influence the scheduling of command
		buffer execution using floating point numbers between 0.0 and 1.0. This
		is required even if there is only a single queue:
		*/
		float queuePriority{ 1.0f };
		for (uint32_t queueFamily : uniqueQueueFamilies)
		{
			VkDeviceQueueCreateInfo queueCreateInfo{};
			queueCreateInfo.sType = VK_STRUCTURE_TYPE_DEVICE_QUEUE_CREATE_INFO;
			queueCreateInfo.queueFamilyIndex = queueFamily;
			queueCreateInfo.queueCount = 1;
			queueCreateInfo.pQueuePriorities = &queuePriority;
			queueCreateInfos.push_back(queueCreateInfo);
		}

		/*
		The next information to specify is the set of device features that we’ll
		be using. These are the features that we queried support for with
		vkGetPhysicalDeviceFeatures, like geometry
		shaders. Right now we don’t need anything special, so we can simply define
		it and leave everything to VK_FALSE.
		*/
		VkPhysicalDeviceFeatures deviceFeatures{};
		deviceFeatures.samplerAnisotropy = VK_TRUE;

		VkDeviceCreateInfo createInfo{};
		createInfo.sType = VK_STRUCTURE_TYPE_DEVICE_CREATE_INFO;
		createInfo.pQueueCreateInfos = queueCreateInfos.data();
		createInfo.queueCreateInfoCount = queueCreateInfos.size();
		createInfo.pEnabledFeatures = &deviceFeatures;
		/*
		The remainder of the information bears a resemblance to the VkInstanceCreateInfo
		struct and requires you to specify extensions and validation layers. The difference
		is that these are device specific this time.
		*/
		createInfo.enabledExtensionCount = deviceExtensions.size();
		createInfo.ppEnabledExtensionNames = deviceExtensions.data();
		/*
		Previous implementations of Vulkan made a distinction between instance and device
		specific validation layers, but this is no longer the case. That means that the
		enabledLayerCount and ppEnabledLayerNames fields of VkDeviceCreateInfo
		are ignored by up-to-date implementations. However, it is still a good idea to
		set them anyway to be compatible with older implementations
		*/
		if (enableValidationLayers)
		{
			createInfo.enabledLayerCount = validationLayers.size();
			createInfo.ppEnabledLayerNames = validationLayers.data();
		}
		else
		{
			createInfo.enabledLayerCount = 0;
		}

		if (vkCreateDevice(physicalDevice, &createInfo, nullptr, &device) != VK_SUCCESS)
		{
			throw std::runtime_error("failed to create logical device!");
		}

		vkGetDeviceQueue(device, indices.grahicsFamily.value(), 0, &graphicsQueue);
		vkGetDeviceQueue(device, indices.presentFamily.value(), 0, &presentQueue);
	}

	void createSwapChain()
	{
		SwapChainSupportDetails swapChainSupport{ querySwapChainSupport(physicalDevice) };
		VkSurfaceFormatKHR surfaceFormat{ chooseSwapSurfaceFormat(swapChainSupport.formats) };
		VkPresentModeKHR presentMode{ chooseSwapPresentMode(swapChainSupport.presentModes) };
		VkExtent2D extent{ chooseSwapExtent(swapChainSupport.capabilities) };
		/*
		simply sticking to this minimum means that we may sometimes have
		to wait on the driver to complete internal operations before we can acquire
		another image to render to. Therefore it is recommended to request at least one
		more image than the minimum:
		*/
		uint32_t imageCount{ swapChainSupport.capabilities.minImageCount + 1 };
		if (swapChainSupport.capabilities.maxImageCount > 0 && imageCount > swapChainSupport.capabilities.maxImageCount)
		{
			imageCount = swapChainSupport.capabilities.maxImageCount;
		}

		VkSwapchainCreateInfoKHR createInfo{};
		createInfo.sType = VK_STRUCTURE_TYPE_SWAPCHAIN_CREATE_INFO_KHR;
		createInfo.surface = surface;
		createInfo.minImageCount = imageCount;
		createInfo.imageFormat = surfaceFormat.format;
		createInfo.imageColorSpace = surfaceFormat.colorSpace;
		createInfo.imageExtent = extent;
		/*
		The imageArrayLayers specifies the amount of layers each image consists of.
		This is always 1 unless you are developing a stereoscopic 3D application. The
		imageUsage bit field specifies what kind of operations we’ll use the images in
		the swap chain for. We’re going to render directly to them, which
		means that they’re used as color attachment. It is also possible that you’ll render
		images to a separate image first to perform operations like post-processing. In
		that case you may use a value like VK_IMAGE_USAGE_TRANSFER_DST_BIT instead
		and use a memory operation to transfer the rendered image to a swap chain
		image.
		*/
		createInfo.imageArrayLayers = 1;
		createInfo.imageUsage = VK_IMAGE_USAGE_COLOR_ATTACHMENT_BIT;

		/*
		we need to specify how to handle swap chain images that will be used
		across multiple queue families. That will be the case in our application if the
		graphics queue family is different from the presentation queue. We’ll be drawing
		on the images in the swap chain from the graphics queue and then submitting
		them on the presentation queue. There are two ways to handle images that are
		accessed from multiple queues:
		• VK_SHARING_MODE_EXCLUSIVE: An image is owned by one queue family
		at a time and ownership must be explicitly transferred before using it in
		another queue family. This option offers the best performance.
		• VK_SHARING_MODE_CONCURRENT: Images can be used across multiple queue
		families without explicit ownership transfers.
		*/
		QueueFamilyIndices indices{ findQueueFamilies(physicalDevice) };
		uint32_t queueFamilyIndices[]{ indices.grahicsFamily.value(), indices.presentFamily.value() };
		if (indices.grahicsFamily != indices.presentFamily)
		{
			createInfo.imageSharingMode = VK_SHARING_MODE_CONCURRENT;
			createInfo.queueFamilyIndexCount = 2;
			createInfo.pQueueFamilyIndices = queueFamilyIndices;
		}
		else
		{
			createInfo.imageSharingMode = VK_SHARING_MODE_EXCLUSIVE;
			createInfo.queueFamilyIndexCount = 0;
			createInfo.pQueueFamilyIndices = nullptr;
		}
		/*
		We can specify that a certain transform should be applied to images in the
		swap chain if it is supported (supportedTransforms in capabilities), like a
		90 degree clockwise rotation or horizontal flip. To specify that you do not want
		any transformation, simply specify the current transformation.
		*/
		createInfo.preTransform = swapChainSupport.capabilities.currentTransform;
		/*
		The compositeAlpha field specifies if the alpha channel should be used for blending
		with other windows in the window system. You’ll almost always want to
		simply ignore the alpha channel, hence VK_COMPOSITE_ALPHA_OPAQUE_BIT_KHR
		*/
		createInfo.compositeAlpha = VK_COMPOSITE_ALPHA_OPAQUE_BIT_KHR;
		createInfo.presentMode = presentMode;
		createInfo.clipped = VK_TRUE;
		/*
		With Vulkan it’s possible that your
		swap chain becomes invalid or unoptimized while your application is running, for
		example because the window was resized. In that case the swap chain actually
		needs to be recreated from scratch and a reference to the old one must be
		specified in this field. This is a complex topic that we’ll learn more about in a
		future chapter. For now we’ll assume that we’ll only ever create one swap chain.
		*/
		createInfo.oldSwapchain = VK_NULL_HANDLE;
		if (vkCreateSwapchainKHR(device, &createInfo, nullptr, &swapChain) != VK_SUCCESS)
		{
			throw std::runtime_error("failed to create swap chain!");
		}
		vkGetSwapchainImagesKHR(device, swapChain, &imageCount, nullptr);
		swapChainImages.resize(imageCount);
		vkGetSwapchainImagesKHR(device, swapChain, &imageCount, swapChainImages.data());
		swapChainImageFormat = surfaceFormat.format;
		swapChainExtent = extent;
	}

	VkSurfaceFormatKHR chooseSwapSurfaceFormat(const std::vector<VkSurfaceFormatKHR>& availableFormats)
	{
		/*
		Each VkSurfaceFormatKHR entry contains a format and a colorSpace member.
		The format member specifies the color channels and types. For example,
		VK_FORMAT_B8G8R8A8_SRGB means that we store the B, G, R and alpha channels
		in that order with an 8 bit unsigned integer for a total of 32 bits per pixel.
		The colorSpace member indicates if the SRGB color space is supported or
		not using the VK_COLOR_SPACE_SRGB_NONLINEAR_KHR flag. Note that this flag
		used to be called VK_COLORSPACE_SRGB_NONLINEAR_KHR in old versions of the
		specification.
		For the color space we’ll use SRGB if it is available, because it results in more
		accurate perceived colors. It is also pretty much the standard color space
		for images, like the textures we’ll use later on. Because of that we should
		also use an SRGB color format, of which one of the most common ones is
		VK_FORMAT_B8G8R8A8_SRGB.
		*/
		for (const auto& availableFormat : availableFormats)
		{
			if (availableFormat.format == VK_FORMAT_B8G8R8A8_SRGB &&
				availableFormat.colorSpace == VK_COLOR_SPACE_SRGB_NONLINEAR_KHR)
			{
				return availableFormat;
			}
		}
		return availableFormats[0];
	}

	VkPresentModeKHR chooseSwapPresentMode(const std::vector<VkPresentModeKHR>& availablePresentModes)
	{
		/*
		The presentation mode is arguably the most important
		setting for the swap chain, because it represents the actual conditions for showing
		images to the screen. There are four possible modes available in Vulkan:
		• VK_PRESENT_MODE_IMMEDIATE_KHR: Images submitted by your application
		are transferred to the screen right away, which may result in tearing.
		• VK_PRESENT_MODE_FIFO_KHR: The swap chain is a queue where the display
		takes an image from the front of the queue when the display is refreshed
		and the program inserts rendered images at the back of the queue. If the
		queue is full then the program has to wait. This is most similar to vertical
		sync as found in modern games. The moment that the display is refreshed
		is known as “vertical blank”.
		• VK_PRESENT_MODE_FIFO_RELAXED_KHR: This mode only differs from the
		previous one if the application is late and the queue was empty at the last
		vertical blank. Instead of waiting for the next vertical blank, the image is
		transferred right away when it finally arrives. This may result in visible
		tearing.
		• VK_PRESENT_MODE_MAILBOX_KHR: This is another variation of the second
		mode. Instead of blocking the application when the queue is full, the
		images that are already queued are simply replaced with the newer ones.
		This mode can be used to render frames as fast as possible while still
		avoiding tearing, resulting in fewer latency issues than standard vertical
		sync. This is commonly known as “triple buffering”, although the existence
		of three buffers alone does not necessarily mean that the framerate
		is unlocked.
		*/
		for (const auto& availablePresentMode : availablePresentModes)
		{
			if (availablePresentMode == VK_PRESENT_MODE_MAILBOX_KHR)
			{
				return availablePresentMode;
			}
		}
		return VK_PRESENT_MODE_FIFO_KHR;
	}

	/*
	The swap extent is the resolution of the swap chain images and it’s almost always
	exactly equal to the resolution of the window that we’re drawing to in pixels
	GLFW uses two units when measuring sizes: pixels and screen coordinates. For
	example, the resolution {WIDTH, HEIGHT} that we specified earlier when creating
	the window is measured in screen coordinates. But Vulkan works with
	pixels, so the swap chain extent must be specified in pixels as well. Unfortunately,
	if you are using a high DPI display (like Apple’s Retina display), screen
	coordinates don’t correspond to pixels. Instead, due to the higher pixel density,
	the resolution of the window in pixel will be larger than the resolution in screen
	coordinates. So if Vulkan doesn’t fix the swap extent for us, we can’t just use
	the original {WIDTH, HEIGHT}. Instead, we must use glfwGetFramebufferSize
	to query the resolution of the window in pixel before matching it against the
	minimum and maximum image extent.
	*/
	VkExtent2D chooseSwapExtent(const VkSurfaceCapabilitiesKHR& capabilities)
	{
		if (capabilities.currentExtent.width != std::numeric_limits<uint32_t>::max())
		{
			return capabilities.currentExtent;
		}
		else
		{
			int width;
			int height;
			glfwGetFramebufferSize(window, &width, &height);
			VkExtent2D actualExtent{
				static_cast<uint32_t>(width),
				static_cast<uint32_t>(height),
			};
			actualExtent.width = std::clamp(
				actualExtent.width,
				capabilities.minImageExtent.width,
				capabilities.maxImageExtent.width
			);
			actualExtent.height = std::clamp(
				actualExtent.height,
				capabilities.minImageExtent.height,
				capabilities.maxImageExtent.height
			);
			return actualExtent;
		}
	}

	void createImageViews()
	{
		swapChainImageViews.resize(swapChainImages.size());
		for (size_t i{ 0 }; i < swapChainImages.size(); i++)
		{
			swapChainImageViews[i] = createImageView(swapChainImages[i], swapChainImageFormat, VK_IMAGE_ASPECT_COLOR_BIT);
			/*
			If you were working on a stereographic 3D application, then you would create
			a swap chain with multiple layers. You could then create multiple image views
			for each image representing the views for the left and right eyes by accessing
			different layers.
			*/
		}
	}

	VkImageView createImageView(VkImage image, VkFormat format, VkImageAspectFlags aspectFlags)
	{
		VkImageViewCreateInfo viewInfo{};
		viewInfo.sType = VK_STRUCTURE_TYPE_IMAGE_VIEW_CREATE_INFO;
		viewInfo.image = image;
		/*
		The viewType and format fields specify how the image data should be interpreted.
		The viewType parameter allows you to treat images as 1D textures, 2D
		textures, 3D textures and cube maps.
		*/
		viewInfo.viewType = VK_IMAGE_VIEW_TYPE_2D;
		viewInfo.format = format;
		/*
		The components field allows you to swizzle the color channels around. For
		example, you can map all of the channels to the red channel for a monochrome
		texture. You can also map constant values of 0 and 1 to a channel. In our case
		we’ll stick to the default mapping.
		*/
		viewInfo.components.r = VK_COMPONENT_SWIZZLE_IDENTITY;
		viewInfo.components.g = VK_COMPONENT_SWIZZLE_IDENTITY;
		viewInfo.components.b = VK_COMPONENT_SWIZZLE_IDENTITY;
		viewInfo.components.a = VK_COMPONENT_SWIZZLE_IDENTITY;
		/*
		The subresourceRange field describes what the image’s purpose is and which
		part of the image should be accessed. Our images will be used as color targets
		without any mipmapping levels or multiple layers.
		*/
		viewInfo.subresourceRange.aspectMask = aspectFlags;
		viewInfo.subresourceRange.baseMipLevel = 0;
		viewInfo.subresourceRange.levelCount = 1;
		viewInfo.subresourceRange.baseArrayLayer = 0;
		viewInfo.subresourceRange.layerCount = 1;

		VkImageView imageView;
		if (vkCreateImageView(device, &viewInfo, nullptr, &imageView) != VK_SUCCESS)
		{
			throw std::runtime_error("failed to create image view!");
		}
		return imageView;
	}

	void createRenderPass()
	{
		VkAttachmentDescription colorAttachment{};
		colorAttachment.format = swapChainImageFormat;
		colorAttachment.samples = VK_SAMPLE_COUNT_1_BIT;
		/*
		The loadOp and storeOp determine what to do with the data in the attachment
		before rendering and after rendering. We have the following choices for loadOp:
		• VK_ATTACHMENT_LOAD_OP_LOAD: Preserve the existing contents of the attachment
		• VK_ATTACHMENT_LOAD_OP_CLEAR: Clear the values to a constant at the
		start
		• VK_ATTACHMENT_LOAD_OP_DONT_CARE: Existing contents are undefined;
		we don’t care about them
		storeOp:
		• VK_ATTACHMENT_STORE_OP_STORE: Rendered contents will be stored in
		memory and can be read later
		• VK_ATTACHMENT_STORE_OP_DONT_CARE: Contents of the framebuffer will
		be undefined after the rendering operation
		*/
		colorAttachment.loadOp = VK_ATTACHMENT_LOAD_OP_CLEAR;
		colorAttachment.storeOp = VK_ATTACHMENT_STORE_OP_STORE;
		/*
		The loadOp and storeOp apply to color and depth data, and stencilLoadOp /
		stencilStoreOp apply to stencil data.
		*/
		colorAttachment.stencilLoadOp = VK_ATTACHMENT_LOAD_OP_DONT_CARE;
		colorAttachment.stencilStoreOp = VK_ATTACHMENT_STORE_OP_DONT_CARE;
		/*
		Textures and framebuffers in Vulkan are represented by VkImage objects with
		a certain pixel format, however the layout of the pixels in memory can change
		based on what you’re trying to do with an image.
		Some of the most common layouts are:
		• VK_IMAGE_LAYOUT_COLOR_ATTACHMENT_OPTIMAL: Images used as color attachment
		• VK_IMAGE_LAYOUT_PRESENT_SRC_KHR: Images to be presented in the swap
		chain
		• VK_IMAGE_LAYOUT_TRANSFER_DST_OPTIMAL: Images to be used as destination
		for a memory copy operation
		*/
		colorAttachment.initialLayout = VK_IMAGE_LAYOUT_UNDEFINED;
		colorAttachment.finalLayout = VK_IMAGE_LAYOUT_PRESENT_SRC_KHR;

		/*
		The initialLayout specifies which layout the image will have before the render
		pass begins. The finalLayout specifies the layout to automatically transition
		to when the render pass finishes. Using VK_IMAGE_LAYOUT_UNDEFINED for
		initialLayout means that we don’t care what previous layout the image was
		in. The caveat of this special value is that the contents of the image are not
		guaranteed to be preserved, but that doesn’t matter since we’re going to clear it
		anyway. We want the image to be ready for presentation using the swap chain
		after rendering, which is why we use VK_IMAGE_LAYOUT_PRESENT_SRC_KHR as
		finalLayout.
		*/

		/*
		A single render pass can consist of multiple subpasses. Subpasses are subsequent
		rendering operations that depend on the contents of framebuffers in previous
		passes, for example a sequence of post-processing effects that are applied one
		after another.
		*/
		VkAttachmentReference colorAttachmentRef{};
		/*
		The attachment parameter specifies which attachment to reference by its
		index in the attachment descriptions array. Our array consists of a single
		VkAttachmentDescription, so its index is 0. The layout specifies which
		layout we would like the attachment to have during a subpass that uses this
		reference. Vulkan will automatically transition the attachment to this layout
		when the subpass is started. We intend to use the attachment to function as
		a color buffer and the VK_IMAGE_LAYOUT_COLOR_ATTACHMENT_OPTIMAL layout
		will give us the best performance, as its name implies.
		*/
		colorAttachmentRef.attachment = 0;
		colorAttachmentRef.layout = VK_IMAGE_LAYOUT_COLOR_ATTACHMENT_OPTIMAL;

		VkAttachmentDescription depthAttachment{};
		/*
		The format should be the same as the depth image itself. This time we don’t
		care about storing the depth data (storeOp), because it will not be used after
		drawing has finished. This may allow the hardware to perform additional optimizations.
		Just like the color buffer, we don’t care about the previous depth
		contents, so we can use VK_IMAGE_LAYOUT_UNDEFINED as initialLayout.
		*/
		depthAttachment.format = findDepthFormat();
		depthAttachment.samples = VK_SAMPLE_COUNT_1_BIT;
		depthAttachment.loadOp = VK_ATTACHMENT_LOAD_OP_CLEAR;
		depthAttachment.storeOp = VK_ATTACHMENT_STORE_OP_DONT_CARE;
		depthAttachment.stencilLoadOp = VK_ATTACHMENT_LOAD_OP_DONT_CARE;
		depthAttachment.stencilStoreOp = VK_ATTACHMENT_STORE_OP_DONT_CARE;
		depthAttachment.initialLayout = VK_IMAGE_LAYOUT_UNDEFINED;
		depthAttachment.finalLayout = VK_IMAGE_LAYOUT_DEPTH_STENCIL_ATTACHMENT_OPTIMAL;

		VkAttachmentReference depthAttachmentRef{};
		depthAttachmentRef.attachment = 1;
		depthAttachmentRef.layout = VK_IMAGE_LAYOUT_DEPTH_STENCIL_ATTACHMENT_OPTIMAL;

		VkSubpassDescription subpass{};
		subpass.pipelineBindPoint = VK_PIPELINE_BIND_POINT_GRAPHICS;
		/*
		The index of the attachment in this array is directly referenced from the fragment
		shader with the layout(location = 0)out vec4 outColor directive!
		The following other types of attachments can be referenced by a subpass:
		• pInputAttachments: Attachments that are read from a shader
		• pResolveAttachments: Attachments used for multisampling color attachments
		• pDepthStencilAttachment: Attachment for depth and stencil data
		• pPreserveAttachments: Attachments that are not used by this subpass,
		but for which the data must be preserved
		*/
		subpass.colorAttachmentCount = 1;
		subpass.pColorAttachments = &colorAttachmentRef;
		subpass.pDepthStencilAttachment = &depthAttachmentRef;

		VkSubpassDependency dependency{};
		/*
		The first two fields specify the indices of the dependency and the dependent subpass.
		The special value VK_SUBPASS_EXTERNAL refers to the implicit subpass before
		or after the render pass depending on whether it is specified in srcSubpass
		or dstSubpass. The index 0 refers to our subpass, which is the first and only
		one. The dstSubpass must always be higher than srcSubpass to prevent cycles
		in the dependency graph (unless one of the subpasses is VK_SUBPASS_EXTERNAL).
		*/
		dependency.srcSubpass = VK_SUBPASS_EXTERNAL;
		dependency.dstSubpass = 0;
		/*
		The next two fields specify the operations to wait on and the stages in which
		these operations occur. We need to wait for the swap chain to finish reading
		from the image before we can access it. This can be accomplished by waiting
		on the color attachment output stage itself.
		*/
		dependency.srcStageMask = VK_PIPELINE_STAGE_COLOR_ATTACHMENT_OUTPUT_BIT |
			VK_PIPELINE_STAGE_EARLY_FRAGMENT_TESTS_BIT;
		dependency.srcAccessMask = 0;
		/*
		The operations that should wait on this are in the color attachment stage and
		involve the writing of the color attachment. These settings will prevent the
		transition from happening until it’s actually necessary (and allowed): when we
		want to start writing colors to it.
		*/
		dependency.dstStageMask = VK_PIPELINE_STAGE_COLOR_ATTACHMENT_OUTPUT_BIT |
			VK_PIPELINE_STAGE_EARLY_FRAGMENT_TESTS_BIT;
		dependency.dstAccessMask = VK_ACCESS_COLOR_ATTACHMENT_WRITE_BIT |
			VK_ACCESS_DEPTH_STENCIL_ATTACHMENT_WRITE_BIT;

		/*
		Finally, we need to extend our subpass dependencies to make sure that there
		is no conflict between the transitioning of the depth image and it being cleared
		as part of its load operation. The depth image is first accessed in the early
		fragment test pipeline stage and because we have a load operation that clears,
		we should specify the access mask for writes.
		*/

		std::array<VkAttachmentDescription, 2> attachments{ {colorAttachment, depthAttachment} };

		VkRenderPassCreateInfo renderPassInfo{};
		renderPassInfo.sType = VK_STRUCTURE_TYPE_RENDER_PASS_CREATE_INFO;
		renderPassInfo.attachmentCount = attachments.size();
		renderPassInfo.pAttachments = attachments.data();
		renderPassInfo.subpassCount = 1;
		renderPassInfo.pSubpasses = &subpass;
		renderPassInfo.dependencyCount = 1;
		renderPassInfo.pDependencies = &dependency;

		if (vkCreateRenderPass(device, &renderPassInfo, nullptr, &renderPass) != VK_SUCCESS)
		{
			throw std::runtime_error("failed creating render pass!");
		}
	}

	void createDescriptorSetLayout()
	{
		VkDescriptorSetLayoutBinding uboLayoutBinding{};
		/*
		The first two fields specify the binding used in the shader and the type of descriptor,
		which is a uniform buffer object. It is possible for the shader variable
		to represent an array of uniform buffer objects, and descriptorCount specifies
		the number of values in the array. This could be used to specify a transformation
		for each of the bones in a skeleton for skeletal animation, for example.
		Our MVP transformation is in a single uniform buffer object, so we’re using a
		descriptorCount of 1.
		*/
		uboLayoutBinding.binding = 0;
		uboLayoutBinding.descriptorType = VK_DESCRIPTOR_TYPE_UNIFORM_BUFFER;
		uboLayoutBinding.descriptorCount = 1;
		/*
		We also need to specify in which shader stages the descriptor is going to be referenced.
		The stageFlags field can be a combination of VkShaderStageFlagBits
		values or the value VK_SHADER_STAGE_ALL_GRAPHICS. In our case, we’re only
		referencing the descriptor from the vertex shader.
		*/
		uboLayoutBinding.stageFlags = VK_SHADER_STAGE_VERTEX_BIT;
		//The pImmutableSamplers field is only relevant for image sampling related descriptors
		uboLayoutBinding.pImmutableSamplers = nullptr;

		VkDescriptorSetLayoutBinding samplerLayoutBinding{};
		samplerLayoutBinding.binding = 1;
		samplerLayoutBinding.descriptorCount = 1;
		samplerLayoutBinding.descriptorType = VK_DESCRIPTOR_TYPE_COMBINED_IMAGE_SAMPLER;
		samplerLayoutBinding.pImmutableSamplers = nullptr;
		/*
		Make sure to set the stageFlags to indicate that we intend to use the combined
		image sampler descriptor in the fragment shader. That’s where the color of the
		fragment is going to be determined. It is possible to use texture sampling in
		the vertex shader, for example to dynamically deform a grid of vertices by a
		heightmap.
		*/
		samplerLayoutBinding.stageFlags = VK_SHADER_STAGE_FRAGMENT_BIT;

		std::array< VkDescriptorSetLayoutBinding, 2> bindings{ uboLayoutBinding, samplerLayoutBinding };

		VkDescriptorSetLayoutCreateInfo layoutInfo{};
		layoutInfo.sType = VK_STRUCTURE_TYPE_DESCRIPTOR_SET_LAYOUT_CREATE_INFO;
		layoutInfo.bindingCount = bindings.size();
		layoutInfo.pBindings = bindings.data();

		if (vkCreateDescriptorSetLayout(device, &layoutInfo, nullptr, &descriptorSetLayout) != VK_SUCCESS)
		{
			throw std::runtime_error("failed to create descriptor set layout!");
		}
	}

	/*
	+------------------+
	| Vertex Input     |  <--- Input data (vertices, indices) FIXED FUNCTION
	+------------------+
			 |
			 v
	+------------------+
	| Vertex Shader    |  <--- Transform and process vertices
	+------------------+
			 |
			 v
	+---------------------------+
	| Tessellation Control Shader|  <--- Optional: control tessellation level
	+---------------------------+
			 |
			 v
	+---------------------------+
	| Tessellation Evaluation    |  <--- Optional: calculate tessellated vertices
	| Shader                    |
	+---------------------------+
			 |
			 v
	+------------------+
	| Geometry Shader |  <--- Optional: generate or modify geometry
	+------------------+
			 |
			 v
	+------------------+
	| Rasterization    |  <--- Convert geometry to fragments/pixels FIXED FUNCTION
	+------------------+
			 |
			 v
	+------------------+
	| Fragment Shader  |  <--- Compute color for each fragment (pixel)
	+------------------+
			 |
			 v
	+----------------------+
	| Color Blending       |  <--- Combine fragment colors with frame buffer FIXED FUNCTION
	+----------------------+
			 |
			 v
	+-------------------+
	| Framebuffer Output |  <--- Final image to the screen 
	+-------------------+

	*/
	void createGraphicsPipeline()
	{
		auto vertShaderCode{ readFile("shaders/vert.spv") };
		auto fragShaderCode{ readFile("shaders/frag.spv") };

		/*
		The compilation and linking of the SPIR-V bytecode to machine code for execution by the GPU
		doesn’t happen until the graphics pipeline is created. That means that we’re allowed
		to destroy the shader modules again as soon as pipeline creation is finished,
		which is why we’ll make them local variables in the createGraphicsPipeline
		function instead of class members:
		*/
		VkShaderModule vertShaderModule{ createShaderModule(vertShaderCode) };
		VkShaderModule fragShaderModule{ createShaderModule(fragShaderCode) };

		VkPipelineShaderStageCreateInfo vertShaderStageInfo{};
		vertShaderStageInfo.sType = VK_STRUCTURE_TYPE_PIPELINE_SHADER_STAGE_CREATE_INFO;
		vertShaderStageInfo.stage = VK_SHADER_STAGE_VERTEX_BIT;
		vertShaderStageInfo.module = vertShaderModule;
		vertShaderStageInfo.pName = "main"; // entrypoint func

		VkPipelineShaderStageCreateInfo fragShaderStageInfo{};
		fragShaderStageInfo.sType = VK_STRUCTURE_TYPE_PIPELINE_SHADER_STAGE_CREATE_INFO;
		fragShaderStageInfo.stage = VK_SHADER_STAGE_FRAGMENT_BIT;
		fragShaderStageInfo.module = fragShaderModule;
		fragShaderStageInfo.pName = "main"; // entrypoint func

		VkPipelineShaderStageCreateInfo shaderStages[] = {vertShaderStageInfo, fragShaderStageInfo};

		auto bindingDescription = Vertex::getBindingDescription();
		auto attributeDescription = Vertex::getAttributeDescription();
		VkPipelineVertexInputStateCreateInfo vertexInputInfo{};
		vertexInputInfo.sType = VK_STRUCTURE_TYPE_PIPELINE_VERTEX_INPUT_STATE_CREATE_INFO;
		vertexInputInfo.vertexBindingDescriptionCount = 1;
		vertexInputInfo.pVertexBindingDescriptions = &bindingDescription;
		vertexInputInfo.vertexAttributeDescriptionCount = attributeDescription.size();
		vertexInputInfo.pVertexAttributeDescriptions = attributeDescription.data();

		/*
		The VkPipelineInputAssemblyStateCreateInfo struct describes two things:
		what kind of geometry will be drawn from the vertices and if primitive restart
		should be enabled. The former is specified in the topology member and can
		have values like:
		• VK_PRIMITIVE_TOPOLOGY_POINT_LIST: points from vertices
		• VK_PRIMITIVE_TOPOLOGY_LINE_LIST: line from every 2 vertices without
		reuse
		• VK_PRIMITIVE_TOPOLOGY_LINE_STRIP: the end vertex of every line is used
		as start vertex for the next line
		• VK_PRIMITIVE_TOPOLOGY_TRIANGLE_LIST: triangle from every 3 vertices
		without reuse
		• VK_PRIMITIVE_TOPOLOGY_TRIANGLE_STRIP: the second and third vertex
		of every triangle are used as first two vertices of the next triangle
		Normally, the vertices are loaded from the vertex buffer by index in sequential
		order, but with an element buffer you can specify the indices to use yourself.
		This allows you to perform optimizations like reusing vertices. If you set the
		primitiveRestartEnable member to VK_TRUE, then it’s possible to break up
		lines and triangles in the _STRIP topology modes by using a special index of
		0xFFFF or 0xFFFFFFFF.
		*/
		VkPipelineInputAssemblyStateCreateInfo inputAssembly{};
		inputAssembly.sType = VK_STRUCTURE_TYPE_PIPELINE_INPUT_ASSEMBLY_STATE_CREATE_INFO;
		inputAssembly.topology = VK_PRIMITIVE_TOPOLOGY_TRIANGLE_LIST;
		inputAssembly.primitiveRestartEnable = VK_FALSE;

		/*
		A viewport basically describes the region of the framebuffer that the output will
		be rendered to. This will almost always be (0, 0) to (width, height)
		*/
		VkViewport viewport{};
		viewport.x = 0.0f;
		viewport.y = 0.0f;
		viewport.width = (float)swapChainExtent.width;
		viewport.height = (float)swapChainExtent.height;
		viewport.minDepth = 0.0f;
		viewport.maxDepth = 1.0f;

		/*
		While viewports define the transformation from the image to the framebuffer,
		scissor rectangles define in which regions pixels will actually be stored. Any
		pixels outside the scissor rectangles will be discarded by the rasterizer. They
		function like a filter rather than a transformation.
		*/
		VkRect2D scissor{};
		scissor.offset = { 0, 0 };
		scissor.extent = swapChainExtent;

		VkPipelineViewportStateCreateInfo viewportState{};
		viewportState.sType = VK_STRUCTURE_TYPE_PIPELINE_VIEWPORT_STATE_CREATE_INFO;
		viewportState.viewportCount = 1;
		viewportState.pViewports = &viewport;
		viewportState.scissorCount = 1;
		viewportState.pScissors = &scissor;

		/*
		The rasterizer takes the geometry that is shaped by the vertices from the
		vertex shader and turns it into fragments to be colored by the fragment
		shader. It also performs depth testing, face culling and the scissor test,
		and it can be configured to output fragments that fill entire polygons
		or just the edges (wireframe rendering).
		*/
		VkPipelineRasterizationStateCreateInfo rasterizer{};
		rasterizer.sType = VK_STRUCTURE_TYPE_PIPELINE_RASTERIZATION_STATE_CREATE_INFO;
		rasterizer.depthClampEnable = VK_FALSE;
		/*
		If rasterizerDiscardEnable is set to VK_TRUE, then geometry never passes
		through the rasterizer stage. This basically disables any output to the framebuffer.
		*/
		rasterizer.rasterizerDiscardEnable = VK_FALSE;
		/*
		The polygonMode determines how fragments are generated for geometry. The
		following modes are available:
		• VK_POLYGON_MODE_FILL: fill the area of the polygon with fragments
		• VK_POLYGON_MODE_LINE: polygon edges are drawn as lines
		• VK_POLYGON_MODE_POINT: polygon vertices are drawn as points
		Using any mode other than fill requires enabling a GPU feature.
		*/
		rasterizer.polygonMode = VK_POLYGON_MODE_FILL;
		/*
		The lineWidth member describes the thickness of lines
		in terms of number of fragments. The maximum line width that is supported
		depends on the hardware and any line thicker than 1.0f requires you to enable
		the wideLines GPU feature.
		*/
		rasterizer.lineWidth = 1.0f;
		/*
		The cullMode variable determines the type of face culling to use. You can
		disable culling, cull the front faces, cull the back faces or both. The frontFace
		variable specifies the vertex order for faces to be considered front-facing and can
		be clockwise or counterclockwise.
		*/
		rasterizer.cullMode = VK_CULL_MODE_BACK_BIT;
		/*
		The problem is that because of the Y-flip we did in the projection matrix,
		the vertices are now being drawn in counter-clockwise order instead of clockwise
		order. This causes backface culling to kick in and prevents any geometry from
		being drawn.
		*/
		rasterizer.frontFace = VK_FRONT_FACE_COUNTER_CLOCKWISE;
		rasterizer.depthBiasEnable = VK_FALSE;
		rasterizer.depthBiasConstantFactor = 0.0f;
		rasterizer.depthBiasClamp = 0.0f;
		rasterizer.depthBiasSlopeFactor = 0.0f;

		/*
		The VkPipelineMultisampleStateCreateInfo struct configures multisampling,
		which is one of the ways to perform anti-aliasing. It works by combining
		the fragment shader results of multiple polygons that rasterize to the same
		pixel. This mainly occurs along edges, which is also where the most noticeable
		aliasing artifacts occur. Because it doesn’t need to run the fragment shader
		multiple times if only one polygon maps to a pixel, it is significantly less
		expensive than simply rendering to a higher resolution and then downscaling.
		Enabling it requires enabling a GPU feature.
		*/
		VkPipelineMultisampleStateCreateInfo multisampling{};
		multisampling.sType = VK_STRUCTURE_TYPE_PIPELINE_MULTISAMPLE_STATE_CREATE_INFO;
		multisampling.sampleShadingEnable = VK_FALSE;
		multisampling.rasterizationSamples = VK_SAMPLE_COUNT_1_BIT;
		multisampling.minSampleShading = 1.0f;
		multisampling.pSampleMask = nullptr;
		multisampling.alphaToCoverageEnable = VK_FALSE;
		multisampling.alphaToOneEnable = VK_FALSE;


		/*
		After a fragment shader has returned a color, it needs to be combined with the
		color that is already in the framebuffer. This transformation is known as color
		blending and there are two ways to do it:
		• Mix the old and new value to produce a final color
		• Combine the old and new value using a bitwise operation
		There are two types of structs to configure color blending. The first struct,
		VkPipelineColorBlendAttachmentState contains the configuration per attached
		framebuffer and the second struct, VkPipelineColorBlendStateCreateInfo
		contains the global color blending settings
		*/
		VkPipelineColorBlendAttachmentState colorBlendAttachement{};
		colorBlendAttachement.colorWriteMask = VK_COLOR_COMPONENT_R_BIT |
			VK_COLOR_COMPONENT_G_BIT | VK_COLOR_COMPONENT_B_BIT |
			VK_COLOR_COMPONENT_A_BIT;
		colorBlendAttachement.blendEnable = VK_FALSE;
		colorBlendAttachement.srcColorBlendFactor = VK_BLEND_FACTOR_ONE;
		colorBlendAttachement.dstColorBlendFactor = VK_BLEND_FACTOR_ZERO;
		colorBlendAttachement.colorBlendOp = VK_BLEND_OP_ADD;
		colorBlendAttachement.srcAlphaBlendFactor = VK_BLEND_FACTOR_ONE;
		colorBlendAttachement.dstAlphaBlendFactor = VK_BLEND_FACTOR_ZERO;
		colorBlendAttachement.alphaBlendOp = VK_BLEND_OP_ADD;

		VkPipelineColorBlendStateCreateInfo colorBlending{};
		colorBlending.sType = VK_STRUCTURE_TYPE_PIPELINE_COLOR_BLEND_STATE_CREATE_INFO;
		colorBlending.logicOpEnable = VK_FALSE;
		colorBlending.logicOp = VK_LOGIC_OP_COPY;
		colorBlending.attachmentCount = 1;
		colorBlending.pAttachments = &colorBlendAttachement;
		colorBlending.blendConstants[0] = 0.0f;
		colorBlending.blendConstants[1] = 0.0f;
		colorBlending.blendConstants[2] = 0.0f;
		colorBlending.blendConstants[3] = 0.0f;

		/*
		While most of the pipeline state needs to be baked into the pipeline state, a
		limited amount of the state can actually be changed without recreating the
		pipeline at draw time. Examples are the size of the viewport, line width and
		blend constants.
		*/
		std::vector<VkDynamicState> dynamicStates{ VK_DYNAMIC_STATE_VIEWPORT, VK_DYNAMIC_STATE_SCISSOR };
		VkPipelineDynamicStateCreateInfo dynamicState{};
		dynamicState.sType = VK_STRUCTURE_TYPE_PIPELINE_DYNAMIC_STATE_CREATE_INFO;
		dynamicState.dynamicStateCount = dynamicStates.size();
		dynamicState.pDynamicStates = dynamicStates.data();

		/*
		You can use uniform values in shaders, which are globals similar to dynamic
		state variables that can be changed at drawing time to alter the behavior of
		your shaders without having to recreate them. They are commonly used to pass
		the transformation matrix to the vertex shader, or to create texture samplers
		in the fragment shader.
		These uniform values need to be specified during pipeline creation by creating a
		VkPipelineLayout object.
		*/
		VkPipelineLayoutCreateInfo pipelineLayoutInfo{};
		pipelineLayoutInfo.sType = VK_STRUCTURE_TYPE_PIPELINE_LAYOUT_CREATE_INFO;
		pipelineLayoutInfo.setLayoutCount = 1;
		pipelineLayoutInfo.pSetLayouts = &descriptorSetLayout;
		// The structure also specifies push constants, which are another way of passing dynamic values to shaders
		pipelineLayoutInfo.pushConstantRangeCount = 0;
		pipelineLayoutInfo.pPushConstantRanges = nullptr;

		if (vkCreatePipelineLayout(device, &pipelineLayoutInfo, nullptr, &pipelineLayout) != VK_SUCCESS)
		{
			throw std::runtime_error("failed to create pipeline layout!");
		}

		/*
		Depth testing needs to be enabled in the graphics pipeline. It is configured through the
		VkPipelineDepthStencilStateCreateInfo struct:
		*/
		VkPipelineDepthStencilStateCreateInfo depthStencil{};
		depthStencil.sType = VK_STRUCTURE_TYPE_PIPELINE_DEPTH_STENCIL_STATE_CREATE_INFO;
		/*
		The depthTestEnable field specifies if the depth of new fragments should
		be compared to the depth buffer to see if they should be discarded. The
		depthWriteEnable field specifies if the new depth of fragments that pass the
		depth test should actually be written to the depth buffer.
		*/
		depthStencil.depthTestEnable = VK_TRUE;
		depthStencil.depthWriteEnable = VK_TRUE;
		/*
		The depthCompareOp field specifies the comparison that is performed to keep
		or discard fragments. We’re sticking to the convention of lower depth = closer,
		so the depth of new fragments should be less.
		*/
		depthStencil.depthCompareOp = VK_COMPARE_OP_LESS;
		/*
		The depthBoundsTestEnable, minDepthBounds and maxDepthBounds fields are
		used for the optional depth bound test. Basically, this allows you to only keep
		fragments that fall within the specified depth range. We won’t be using this
		functionality.
		*/
		depthStencil.depthBoundsTestEnable = VK_FALSE;
		depthStencil.minDepthBounds = 0.0f;
		depthStencil.maxDepthBounds = 1.0f;
		depthStencil.stencilTestEnable = VK_FALSE;
		depthStencil.front = {};
		depthStencil.back = {};

		/*
		We can now combine all of the structures and objects from the previous chapters
		to create the graphics pipeline! Here’s the types of objects we have now, as a
		quick recap:
		• Shader stages: the shader modules that define the functionality of the
		programmable stages of the graphics pipeline
		• Fixed-function state: all of the structures that define the fixed-function
		stages of the pipeline, like input assembly, rasterizer, viewport and color
		blending
		• Pipeline layout: the uniform and push values referenced by the shader
		that can be updated at draw time
		• Render pass: the attachments referenced by the pipeline stages and their
		usage
		*/

		VkGraphicsPipelineCreateInfo pipelineInfo{};
		pipelineInfo.sType = VK_STRUCTURE_TYPE_GRAPHICS_PIPELINE_CREATE_INFO;
		pipelineInfo.stageCount = 2;
		pipelineInfo.pStages = shaderStages;
		pipelineInfo.pVertexInputState = &vertexInputInfo;
		pipelineInfo.pInputAssemblyState = &inputAssembly;
		pipelineInfo.pViewportState = &viewportState;
		pipelineInfo.pRasterizationState = &rasterizer;
		pipelineInfo.pMultisampleState = &multisampling;
		pipelineInfo.pDepthStencilState = &depthStencil;
		pipelineInfo.pColorBlendState = &colorBlending;
		pipelineInfo.pDynamicState = &dynamicState;
		pipelineInfo.layout = pipelineLayout;
		pipelineInfo.renderPass = renderPass;
		pipelineInfo.subpass = 0; //index of the sub pass
		/*
		Vulkan allows you to create a new graphics pipeline by
		deriving from an existing pipeline. The idea of pipeline derivatives is that
		it is less expensive to set up pipelines when they have much functionality in
		common with an existing pipeline and switching between pipelines from the
		same parent can also be done quicker. You can either specify the handle of an
		existing pipeline with basePipelineHandle or reference another pipeline that
		is about to be created by index with basePipelineIndex. Right now there is
		only a single pipeline, so we’ll simply specify a null handle and an invalid index.
		These values are only used if the VK_PIPELINE_CREATE_DERIVATIVE_BIT flag
		is also specified in the flags field of VkGraphicsPipelineCreateInfo.
		*/
		pipelineInfo.basePipelineHandle = VK_NULL_HANDLE;
		pipelineInfo.basePipelineIndex = -1;

		if (vkCreateGraphicsPipelines(device, VK_NULL_HANDLE, 1, &pipelineInfo, nullptr, &graphicsPipeline) != VK_SUCCESS)
		{
			throw std::runtime_error("failed to create graphics pipeline!");
		}

		vkDestroyShaderModule(device, vertShaderModule, nullptr);
		vkDestroyShaderModule(device, fragShaderModule, nullptr);
	}

	VkShaderModule createShaderModule(const std::vector<char>& code)
	{
		VkShaderModuleCreateInfo createInfo{};
		createInfo.sType = VK_STRUCTURE_TYPE_SHADER_MODULE_CREATE_INFO;
		createInfo.codeSize = code.size();
		/*
		the size of the bytecode is specified in bytes, but the bytecode pointer is a uint32_t pointer
		rather than a char pointer. Therefore we will need to cast the pointer with
		reinterpret_cast as shown below. When you perform a cast like this, you also
		need to ensure that the data satisfies the alignment requirements of uint32_t.
		Lucky for us, the data is stored in an std::vector where the default allocator
		already ensures that the data satisfies the worst case alignment requirements.
		*/
		createInfo.pCode = reinterpret_cast<const uint32_t*>(code.data());
		VkShaderModule shaderModule;
		if (vkCreateShaderModule(device, &createInfo, nullptr, &shaderModule) != VK_SUCCESS)
		{
			std::runtime_error("failed to create shader module!");
		}
		return shaderModule;
	}

	void createFramebuffers()
	{
		swapChainFramebuffers.resize(swapChainImageViews.size());
		for (size_t i{ 0 }; i < swapChainImageViews.size(); i++)
		{
			std::array<VkImageView, 2> attachments{ {swapChainImageViews[i], depthImageView} };
			VkFramebufferCreateInfo framebufferInfo{};
			framebufferInfo.sType = VK_STRUCTURE_TYPE_FRAMEBUFFER_CREATE_INFO;
			framebufferInfo.renderPass = renderPass;
			framebufferInfo.attachmentCount = attachments.size();
			framebufferInfo.pAttachments = attachments.data();
			framebufferInfo.width = swapChainExtent.width;
			framebufferInfo.height = swapChainExtent.height;
			framebufferInfo.layers = 1;

			if (vkCreateFramebuffer(device, &framebufferInfo, nullptr, &swapChainFramebuffers[i]) != VK_SUCCESS)
			{
				throw std::runtime_error("failed to create framebuffer!");
			}
		}
	}

	void createCommandPool()
	{
		QueueFamilyIndices queueFamilyIndices{ findQueueFamilies(physicalDevice) };
		VkCommandPoolCreateInfo poolInfo{};
		poolInfo.sType = VK_STRUCTURE_TYPE_COMMAND_POOL_CREATE_INFO;
		/*
		There are two possible flags for command pools:
		• VK_COMMAND_POOL_CREATE_TRANSIENT_BIT: Hint that command buffers
		are rerecorded with new commands very often (may change memory allocation
		behavior)
		• VK_COMMAND_POOL_CREATE_RESET_COMMAND_BUFFER_BIT: Allow command
		buffers to be rerecorded individually, without this flag they all have
		to be reset together
		We will be recording a command buffer every frame, so we want to be able to reset
		and rerecord over it. Thus, we need to set the VK_COMMAND_POOL_CREATE_RESET_COMMAND_BUFFER_BIT
		flag bit for our command pool.
		Command buffers are executed
		*/
		poolInfo.flags = VK_COMMAND_POOL_CREATE_RESET_COMMAND_BUFFER_BIT;
		// We’re going to record commands for drawing, which is why we’ve chosen the graphics queue family.
		poolInfo.queueFamilyIndex = queueFamilyIndices.grahicsFamily.value();

		if (vkCreateCommandPool(device, &poolInfo, nullptr, &commandPool) != VK_SUCCESS)
		{
			throw std::runtime_error("failed to create command pool!");
		}
	}

	void createDepthResources()
	{
		VkFormat depthFormat{ findDepthFormat() };
		createImage(swapChainExtent.width, swapChainExtent.height, depthFormat, VK_IMAGE_TILING_OPTIMAL,
			VK_IMAGE_USAGE_DEPTH_STENCIL_ATTACHMENT_BIT, VK_MEMORY_PROPERTY_DEVICE_LOCAL_BIT,
			depthImage, depthImageMemory);
		depthImageView = createImageView(depthImage, depthFormat, VK_IMAGE_ASPECT_DEPTH_BIT);

		transitionImageLayout(depthImage, depthFormat, VK_IMAGE_LAYOUT_UNDEFINED, VK_IMAGE_LAYOUT_DEPTH_STENCIL_ATTACHMENT_OPTIMAL);
	}

	VkFormat findDepthFormat()
	{
		return findSupportedFormat(
			{ VK_FORMAT_D32_SFLOAT, VK_FORMAT_D32_SFLOAT_S8_UINT, VK_FORMAT_D24_UNORM_S8_UINT },
			VK_IMAGE_TILING_OPTIMAL,
			VK_FORMAT_FEATURE_DEPTH_STENCIL_ATTACHMENT_BIT
		);
	}

	bool hasStencilComponent(VkFormat format)
	{
		return format == VK_FORMAT_D32_SFLOAT_S8_UINT || format == VK_FORMAT_D24_UNORM_S8_UINT;
	}

	VkFormat findSupportedFormat(const std::vector<VkFormat>& candidates, VkImageTiling tiling, VkFormatFeatureFlags features)
	{
		for (VkFormat format : candidates)
		{
			VkFormatProperties props;
			vkGetPhysicalDeviceFormatProperties(physicalDevice, format, &props);
			/*
			The VkFormatProperties struct contains three fields:
			• linearTilingFeatures: Use cases that are supported with linear tiling
			• optimalTilingFeatures: Use cases that are supported with optimal
			tiling
			• bufferFeatures: Use cases that are supported for buffers
			Only the first two are relevant here, and the one we check depends on the tiling
			parameter of the function:
			*/
			if (tiling == VK_IMAGE_TILING_LINEAR && (props.linearTilingFeatures & features) == features)
			{
				return format;
			}
			else if (tiling == VK_IMAGE_TILING_OPTIMAL && (props.optimalTilingFeatures & features) == features)
			{
				return format;
			}
		}
		throw std::runtime_error("failed to find supported format!");
	}

	void createTextureImage()
	{
		int texWidth;
		int texHeight;
		int texChannels;
		stbi_uc* pixels{ stbi_load("textures/texture.jpg", &texWidth, &texHeight, &texChannels, STBI_rgb_alpha) };
		/*
		The pointer that is
		returned is the first element in an array of pixel values. The pixels are laid out
		row by row with 4 bytes per pixel in the case of STBI_rgb_alpha for a total of
		texWidth * texHeight * 4 values.
		*/
		VkDeviceSize imageSize{ texWidth * texHeight * static_cast <VkDeviceSize>(4) };
		if (!pixels)
		{
			throw std::runtime_error("failed to load texture image!");
		}

		VkBuffer stagingBuffer;
		VkDeviceMemory stagingBufferMemory;
		createBuffer(imageSize, VK_BUFFER_USAGE_TRANSFER_SRC_BIT,
			VK_MEMORY_PROPERTY_HOST_VISIBLE_BIT | VK_MEMORY_PROPERTY_HOST_COHERENT_BIT,
			stagingBuffer, stagingBufferMemory);
		void* data;
		vkMapMemory(device, stagingBufferMemory, 0, imageSize, 0, &data);
		memcpy(data, pixels, imageSize);
		vkUnmapMemory(device, stagingBufferMemory);
		stbi_image_free(pixels);

		createImage(texWidth, texHeight, VK_FORMAT_R8G8B8A8_SRGB,
			VK_IMAGE_TILING_OPTIMAL, VK_IMAGE_USAGE_TRANSFER_DST_BIT |
			VK_IMAGE_USAGE_SAMPLED_BIT, VK_MEMORY_PROPERTY_DEVICE_LOCAL_BIT, textureImage, textureImageMemory);

		/*
		The next step is to copy the staging
		buffer to the texture image. This involves two steps:
		• Transition the texture image to VK_IMAGE_LAYOUT_TRANSFER_DST_OPTIMAL
		• Execute the buffer to image copy operation
		*/
		transitionImageLayout(textureImage, VK_FORMAT_R8G8B8A8_SRGB, VK_IMAGE_LAYOUT_UNDEFINED, VK_IMAGE_LAYOUT_TRANSFER_DST_OPTIMAL);
		copyBufferToImage(stagingBuffer, textureImage, texWidth, texHeight);
		/*
		To be able to start sampling from the texture image in the shader, we need one
		last transition to prepare it for shader access
		*/
		transitionImageLayout(textureImage, VK_FORMAT_R8G8B8A8_SRGB, VK_IMAGE_LAYOUT_TRANSFER_DST_OPTIMAL, VK_IMAGE_LAYOUT_SHADER_READ_ONLY_OPTIMAL);

		vkDestroyBuffer(device, stagingBuffer, nullptr);
		vkFreeMemory(device, stagingBufferMemory, nullptr);
	}

	void createImage(uint32_t width, uint32_t height, VkFormat format, VkImageTiling tiling,
		VkImageUsageFlags usage, VkMemoryPropertyFlags properties, VkImage& image,
		VkDeviceMemory& imageMemory)
	{
		VkImageCreateInfo imageInfo{};
		imageInfo.sType = VK_STRUCTURE_TYPE_IMAGE_CREATE_INFO;
		/*
		The image type, specified in the imageType field, tells Vulkan with what kind
		of coordinate system the texels in the image are going to be addressed. It is
		possible to create 1D, 2D and 3D images. One dimensional images can be used
		to store an array of data or gradient, two dimensional images are mainly used
		for textures, and three dimensional images can be used to store voxel volumes,
		for example. The extent field specifies the dimensions of the image, basically
		how many texels there are on each axis. That’s why depth must be 1 instead
		of 0. Our texture will not be an array and we won’t be using mipmapping for
		now.
		*/
		imageInfo.imageType = VK_IMAGE_TYPE_2D;
		imageInfo.extent.width = width;
		imageInfo.extent.height = height;
		imageInfo.extent.depth = 1;
		imageInfo.mipLevels = 1;
		imageInfo.arrayLayers = 1;
		imageInfo.format = format;
		/*
		The tiling field can have one of two values:
		• VK_IMAGE_TILING_LINEAR: Texels are laid out in row-major order like our
		pixels array
		• VK_IMAGE_TILING_OPTIMAL: Texels are laid out in an implementation defined
		order for optimal access
		Unlike the layout of an image, the tiling mode cannot be changed at a later
		time. If you want to be able to directly access texels in the memory of the
		image, then you must use VK_IMAGE_TILING_LINEAR. We will be using a staging
		buffer instead of a staging image, so this won’t be necessary. We will be using
		VK_IMAGE_TILING_OPTIMAL for efficient access from the shader.
		*/
		imageInfo.tiling = tiling;
		/*
		There are only two possible values for the initialLayout of an image:
		• VK_IMAGE_LAYOUT_UNDEFINED: Not usable by the GPU and the very first
		transition will discard the texels.
		• VK_IMAGE_LAYOUT_PREINITIALIZED: Not usable by the GPU, but the first
		transition will preserve the texels.
		191
		There are few situations where it is necessary for the texels to be preserved
		during the first transition. One example, however, would be if you wanted to use
		an image as a staging image in combination with the VK_IMAGE_TILING_LINEAR
		layout. In that case, you’d want to upload the texel data to it and then transition
		the image to be a transfer source without losing the data. In our case, however,
		we’re first going to transition the image to be a transfer destination and then
		copy texel data to it from a buffer object, so we don’t need this property and
		can safely use VK_IMAGE_LAYOUT_UNDEFINED.
		*/
		imageInfo.initialLayout = VK_IMAGE_LAYOUT_UNDEFINED;
		/*
		The usage field has the same semantics as the one during buffer creation.
		The image is going to be used as destination for the buffer copy, so it should
		be set up as a transfer destination. We also want to be able to access
		the image from the shader to color our mesh, so the usage should include
		VK_IMAGE_USAGE_SAMPLED_BIT.
		*/
		imageInfo.usage = usage;
		/*
		The image will only be used by one queue family: the one that supports graphics
		(and therefore also) transfer operations.
		*/
		imageInfo.sharingMode = VK_SHARING_MODE_EXCLUSIVE;
		/*
		The samples flag is related to multisampling. This is only relevant for images
		that will be used as attachments, so stick to one sample. There are some optional
		flags for images that are related to sparse images. Sparse images are images
		where only certain regions are actually backed by memory. If you were using
		a 3D texture for a voxel terrain, for example, then you could use this to avoid
		allocating memory to store large volumes of “air” values. We won’t be using it
		in this tutorial, so leave it to its default value of 0.
		*/
		imageInfo.samples = VK_SAMPLE_COUNT_1_BIT;
		imageInfo.flags = 0;

		if (vkCreateImage(device, &imageInfo, nullptr, &image) != VK_SUCCESS)
		{
			throw std::runtime_error("failed to create iamge!");
		}

		VkMemoryRequirements memRequirements;
		vkGetImageMemoryRequirements(device, image, &memRequirements);
		VkMemoryAllocateInfo allocInfo{};
		allocInfo.sType = VK_STRUCTURE_TYPE_MEMORY_ALLOCATE_INFO;
		allocInfo.allocationSize = memRequirements.size;
		allocInfo.memoryTypeIndex = findMemoryType(memRequirements.memoryTypeBits,
			VK_MEMORY_PROPERTY_DEVICE_LOCAL_BIT);

		if (vkAllocateMemory(device, &allocInfo, nullptr, &imageMemory) != VK_SUCCESS)
		{
			throw std::runtime_error("failed to allocate image memory!");
		}

		vkBindImageMemory(device, image, imageMemory, 0);
	}

	void transitionImageLayout(VkImage image, VkFormat format, VkImageLayout oldLayout, VkImageLayout newLayout)
	{
		VkCommandBuffer commandBuffer{ beginSingleTimeCommands() };
		/*
		One of the most common ways to perform layout transitions is using an image
		memory barrier. A pipeline barrier like that is generally used to synchronize
		access to resources, like ensuring that a write to a buffer completes before reading
		from it, but it can also be used to transition image layouts and transfer
		queue family ownership when VK_SHARING_MODE_EXCLUSIVE is used. There is
		an equivalent buffer memory barrier to do this for buffers.
		*/
		VkImageMemoryBarrier barrier{};
		barrier.sType = VK_STRUCTURE_TYPE_IMAGE_MEMORY_BARRIER;
		/*
		The first two fields specify layout transition. It is possible to use
		VK_IMAGE_LAYOUT_UNDEFINED as oldLayout if you don’t care about the
		existing contents of the image.
		*/
		barrier.oldLayout = oldLayout;
		barrier.newLayout = newLayout;
		/*
		If you are using the barrier to transfer queue family ownership, then these
		two fields should be the indices of the queue families. They must be set to
		VK_QUEUE_FAMILY_IGNORED if you don’t want to do this (not the default value!).
		*/
		barrier.srcQueueFamilyIndex = VK_QUEUE_FAMILY_IGNORED;
		barrier.dstQueueFamilyIndex = VK_QUEUE_FAMILY_IGNORED;
		barrier.image = image;
		/*
		The image and subresourceRange specify the image that is affected and the
		specific part of the image. Our image is not an array and does not have mipmapping
		levels, so only one level and layer are specified.
		*/
		barrier.subresourceRange.aspectMask = VK_IMAGE_ASPECT_COLOR_BIT;
		barrier.subresourceRange.baseMipLevel = 0;
		barrier.subresourceRange.levelCount = 1;
		barrier.subresourceRange.baseArrayLayer = 0;
		barrier.subresourceRange.layerCount = 1;
		/*
		We still need to set access masks and pipeline stages based on the
		layouts in the transition.
		There are two transitions we need to handle:
		• Undefined → transfer destination: transfer writes that don’t need to wait
		on anything
		• Transfer destination → shader reading: shader reads should wait on transfer
		writes, specifically the shader reads in the fragment shader, because
		that’s where we’re going to use the texture
		These rules are specified using the following access masks and pipeline stages:
		*/
		VkPipelineStageFlags sourceStage;
		VkPipelineStageFlags destinationStage;

		if (newLayout == VK_IMAGE_LAYOUT_DEPTH_STENCIL_ATTACHMENT_OPTIMAL)
		{
			barrier.subresourceRange.aspectMask = VK_IMAGE_ASPECT_DEPTH_BIT;
			if (hasStencilComponent(format))
			{
				barrier.subresourceRange.aspectMask |= VK_IMAGE_ASPECT_STENCIL_BIT;
			}
		}
		else
		{
			barrier.subresourceRange.aspectMask = VK_IMAGE_ASPECT_COLOR_BIT;
		}

		if (oldLayout == VK_IMAGE_LAYOUT_UNDEFINED && newLayout == VK_IMAGE_LAYOUT_TRANSFER_DST_OPTIMAL)
		{
			barrier.srcAccessMask = 0;
			barrier.dstAccessMask = VK_ACCESS_TRANSFER_WRITE_BIT;
			sourceStage = VK_PIPELINE_STAGE_TOP_OF_PIPE_BIT;
			destinationStage = VK_PIPELINE_STAGE_TRANSFER_BIT;
		}
		else if (oldLayout == VK_IMAGE_LAYOUT_TRANSFER_DST_OPTIMAL && newLayout == VK_IMAGE_LAYOUT_SHADER_READ_ONLY_OPTIMAL)
		{
			barrier.srcAccessMask = VK_ACCESS_TRANSFER_WRITE_BIT;
			barrier.dstAccessMask = VK_ACCESS_SHADER_READ_BIT;
			sourceStage = VK_PIPELINE_STAGE_TRANSFER_BIT;
			destinationStage = VK_PIPELINE_STAGE_FRAGMENT_SHADER_BIT;
		}
		else if (oldLayout == VK_IMAGE_LAYOUT_UNDEFINED && newLayout == VK_IMAGE_LAYOUT_DEPTH_STENCIL_ATTACHMENT_OPTIMAL)
		{
			/*
			The depth buffer will be read from to perform depth tests to see if a fragment
			is visible, and will be written to when a new fragment is drawn. The reading
			happens in the VK_PIPELINE_STAGE_EARLY_FRAGMENT_TESTS_BIT stage and the
			writing in the VK_PIPELINE_STAGE_LATE_FRAGMENT_TESTS_BIT. You should
			pick the earliest pipeline stage that matches the specified operations, so that it
			is ready for usage as depth attachment when it needs to be.
			*/
			barrier.srcAccessMask = 0;
			barrier.dstAccessMask = VK_ACCESS_DEPTH_STENCIL_ATTACHMENT_READ_BIT |
				VK_ACCESS_DEPTH_STENCIL_ATTACHMENT_WRITE_BIT;
			sourceStage = VK_PIPELINE_STAGE_TOP_OF_PIPE_BIT;
			destinationStage = VK_PIPELINE_STAGE_EARLY_FRAGMENT_TESTS_BIT;
		}
		else
		{
			throw std::invalid_argument("unsupported layout transistion!");
		}

		/*
		All types of pipeline barriers are submitted using the same function. The first parameter
		after the command buffer specifies in which pipeline stage the operations
		occur that should happen before the barrier. The second parameter specifies the
		pipeline stage in which operations will wait on the barrier. The pipeline stages
		that you are allowed to specify before and after the barrier depend on how you
		use the resource before and after the barrier. The allowed values are listed in this
		table of the specification 
		(https://docs.vulkan.org/spec/latest/chapters/synchronization.html#synchronization-access-types-supported). 
		For example, if you’re going to read from a uniform
		after the barrier, you would specify a usage of VK_ACCESS_UNIFORM_READ_BIT
		and the earliest shader that will read from the uniform as pipeline stage, for
		example VK_PIPELINE_STAGE_FRAGMENT_SHADER_BIT. It would not make sense
		to specify a non-shader pipeline stage for this type of usage and the validation
		layers will warn you when you specify a pipeline stage that does not match the
		type of usage.
		The third parameter is either 0 or VK_DEPENDENCY_BY_REGION_BIT. The latter
		turns the barrier into a per-region condition. That means that the implementation
		is allowed to already begin reading from the parts of a resource that were
		written so far, for example.
		The last three pairs of parameters reference arrays of pipeline barriers of the
		three available types: memory barriers, buffer memory barriers, and image
		memory barriers like the one we’re using here. Note that we’re not using the
		VkFormat parameter yet, but we’ll be using that one for special transitions in
		the depth buffer chapter.
		*/
		vkCmdPipelineBarrier(
			commandBuffer,
			sourceStage, destinationStage,
			0,
			0, nullptr,
			0, nullptr,
			1, &barrier
		);

		endSingleTimeCommands(commandBuffer);
	}

	void copyBufferToImage(VkBuffer buffer, VkImage image, uint32_t width, uint32_t height)
	{
		VkCommandBuffer commandBuffer{ beginSingleTimeCommands() };

		VkBufferImageCopy region{};
		/*
		The bufferOffset specifies the byte
		offset in the buffer at which the pixel values start. The bufferRowLength and
		bufferImageHeight fields specify how the pixels are laid out in memory. For
		example, you could have some padding bytes between rows of the image. Specifying
		0 for both indicates that the pixels are simply tightly packed like they
		are in our case. The imageSubresource, imageOffset and imageExtent fields
		indicate to which part of the image we want to copy the pixels.
		*/
		region.bufferOffset = 0;
		region.bufferRowLength = 0;
		region.bufferImageHeight = 0;
		region.imageSubresource.aspectMask = VK_IMAGE_ASPECT_COLOR_BIT;
		region.imageSubresource.mipLevel = 0;
		region.imageSubresource.baseArrayLayer = 0;
		region.imageSubresource.layerCount = 1;
		region.imageOffset = { 0, 0, 0 };
		region.imageExtent = {
			width,
			height,
			1
		};

		vkCmdCopyBufferToImage(
			commandBuffer,
			buffer,
			image,
			VK_IMAGE_LAYOUT_TRANSFER_DST_OPTIMAL,
			1,
			&region
		);

		endSingleTimeCommands(commandBuffer);
	}

	void createTextureImageView()
	{
		textureImageView = createImageView(textureImage, VK_FORMAT_R8G8B8A8_SRGB, VK_IMAGE_ASPECT_COLOR_BIT);
	}

	void createTextureSampler()
	{
		VkSamplerCreateInfo samplerInfo{};
		samplerInfo.sType = VK_STRUCTURE_TYPE_SAMPLER_CREATE_INFO;
		/*
		The magFilter and minFilter fields specify how to interpolate texels that
		are magnified or minified. Magnification concerns the oversampling
		and minification concerns undersampling. The choices are
		VK_FILTER_NEAREST and VK_FILTER_LINEAR,
		*/
		samplerInfo.magFilter = VK_FILTER_LINEAR;
		samplerInfo.minFilter = VK_FILTER_LINEAR;
		/*
		The addressing mode can be specified per axis using the addressMode fields.
		The available values are listed below.
		Note that the axes are called U, V and W instead of X, Y and Z.
		This is a convention for texture space coordinates.
		• VK_SAMPLER_ADDRESS_MODE_REPEAT: Repeat the texture when going beyond
		the image dimensions.
		• VK_SAMPLER_ADDRESS_MODE_MIRRORED_REPEAT: Like repeat, but inverts
		the coordinates to mirror the image when going beyond the dimensions.
		• VK_SAMPLER_ADDRESS_MODE_CLAMP_TO_EDGE: Take the color of the edge
		closest to the coordinate beyond the image dimensions.
		• VK_SAMPLER_ADDRESS_MODE_MIRROR_CLAMP_TO_EDGE: Like clamp to edge,
		but instead uses the edge opposite to the closest edge.
		• VK_SAMPLER_ADDRESS_MODE_CLAMP_TO_BORDER: Return
		*/
		samplerInfo.addressModeU = VK_SAMPLER_ADDRESS_MODE_REPEAT;
		samplerInfo.addressModeV = VK_SAMPLER_ADDRESS_MODE_REPEAT;
		samplerInfo.addressModeW = VK_SAMPLER_ADDRESS_MODE_REPEAT;
		/*
		These two fields specify if anisotropic filtering should be used. There is no reason
		not to use this unless performance is a concern. The maxAnisotropy field limits
		the amount of texel samples that can be used to calculate the final color. A
		lower value results in better performance, but lower quality results. To figure
		out which value we can use, we need to retrieve the properties of the physical
		device
		*/
		samplerInfo.anisotropyEnable = VK_TRUE;

		VkPhysicalDeviceProperties properties{};
		vkGetPhysicalDeviceProperties(physicalDevice, &properties);
		samplerInfo.maxAnisotropy = properties.limits.maxSamplerAnisotropy;
		/*
		The borderColor field specifies which color is returned when sampling beyond
		the image with clamp to border addressing mode. It is possible to return black,
		white or transparent in either float or int formats. You cannot specify an arbitrary
		color.
		*/
		samplerInfo.borderColor = VK_BORDER_COLOR_INT_OPAQUE_BLACK;
		/*
		The unnormalizedCoordinates field specifies which coordinate system you
		want to use to address texels in an image. If this field is VK_TRUE, then you
		can simply use coordinates within the [0, texWidth) and [0, texHeight)
		range. If it is VK_FALSE, then the texels are addressed using the [0, 1) range
		on all axes. Real-world applications almost always use normalized coordinates,
		because then it’s possible to use textures of varying resolutions with the exact
		same coordinates.
		*/
		samplerInfo.unnormalizedCoordinates = VK_FALSE;
		samplerInfo.compareEnable = VK_FALSE;
		/*
		If a comparison function is enabled, then texels will first be compared to a value,
		and the result of that comparison is used in filtering operations. This is mainly
		used for percentage-closer filtering on shadow maps
		*/
		samplerInfo.compareOp = VK_COMPARE_OP_ALWAYS;
		samplerInfo.mipmapMode = VK_SAMPLER_MIPMAP_MODE_LINEAR;
		samplerInfo.mipLodBias = 0.0f;
		samplerInfo.minLod = 0.0f;
		samplerInfo.maxLod = 0.0f;

		if (vkCreateSampler(device, &samplerInfo, nullptr, &textureSampler) != VK_SUCCESS)
		{
			throw std::runtime_error("failed to create texture sampler!");
		}
	}

	void createVertexBuffer()
	{
		VkDeviceSize bufferSize{ sizeof(vertices[0]) * vertices.size() };

		VkBuffer stagingBuffer;
		VkDeviceMemory stagingBufferMemory;
		/*
		VK_BUFFER_USAGE_TRANSFER_SRC_BIT: Buffer can be used as source in a
		memory transfer operation.
		*/
		createBuffer(bufferSize, VK_BUFFER_USAGE_TRANSFER_SRC_BIT,
			VK_MEMORY_PROPERTY_HOST_VISIBLE_BIT | VK_MEMORY_PROPERTY_HOST_COHERENT_BIT,
			stagingBuffer, stagingBufferMemory);

		/*
		This function allows us to access a region of the specified memory resource defined
		by an offset and size. The offset and size here are 0 and bufferInfo.size,
		respectively. It is also possible to specify the special value VK_WHOLE_SIZE to
		map all of the memory. The second to last parameter can be used to specify
		flags, but there aren’t any available yet in the current API. It must be set to the
		value 0. The last parameter specifies the output for the pointer to the mapped
		memory.
		*/
		void* data;
		vkMapMemory(device, stagingBufferMemory, 0, bufferSize, 0, &data);
		/*
		You can now simply memcpy the vertex data to the mapped memory and unmap
		it again using vkUnmapMemory. Unfortunately the driver may not immediately
		copy the data into the buffer memory, for example because of caching. It is also
		possible that writes to the buffer are not visible in the mapped memory yet.
		There are two ways to deal with that problem:
		• Use a memory heap that is host coherent, indicated with VK_MEMORY_PROPERTY_HOST_COHERENT_BIT
		• Call vkFlushMappedMemoryRanges after writing to the mapped memory,
		and call vkInvalidateMappedMemoryRanges before reading from the
		mapped memory
		We went for the first approach, which ensures that the mapped memory always
		matches the contents of the allocated memory. Do keep in mind that this may
		lead to slightly worse performance than explicit flushing
		*/
		memcpy(data, vertices.data(), (size_t)bufferSize);
		vkUnmapMemory(device, stagingBufferMemory);

		/*
		Flushing memory ranges or using a coherent memory heap means that the driver
		will be aware of our writes to the buffer, but it doesn’t mean that they are
		actually visible on the GPU yet. The transfer of data to the GPU is an operation
		that happens in the background and the specification simply tells us that it is
		guaranteed to be complete as of the next call to vkQueueSubmit.
		*/

		/*
		VK_BUFFER_USAGE_TRANSFER_DST_BIT: Buffer can be used as destination
		in a memory transfer operation.
		The vertexBuffer is now allocated from a memory type that is device local,
		which generally means that we’re not able to use vkMapMemory.
		*/
		createBuffer(bufferSize, VK_BUFFER_USAGE_TRANSFER_DST_BIT | VK_BUFFER_USAGE_VERTEX_BUFFER_BIT,
			VK_MEMORY_PROPERTY_DEVICE_LOCAL_BIT,
			vertexBuffer, vertexBufferMemory);

		/*
		A single vertex buffer works correctly, but the memory type that
		allows us to access it from the CPU may not be the most optimal memory type
		for the graphics card itself to read from. The most optimal memory has the
		VK_MEMORY_PROPERTY_DEVICE_LOCAL_BIT flag and is usually not accessible by
		the CPU on dedicated graphics cards. We’ve created two vertex buffers.
		One staging buffer in CPU accessible memory to upload the
		data from the vertex array to, and the final vertex buffer in device local memory.
		We’ll then use a buffer copy command to move the data from the staging buffer
		to the actual vertex buffer.
		*/
		copyBuffer(stagingBuffer, vertexBuffer, bufferSize);

		vkDestroyBuffer(device, stagingBuffer, nullptr);
		vkFreeMemory(device, stagingBufferMemory, nullptr);
	}

	void createBuffer(VkDeviceSize size, VkBufferUsageFlags usage, VkMemoryPropertyFlags properties,
		VkBuffer& buffer, VkDeviceMemory& bufferMemory)
	{
		VkBufferCreateInfo bufferInfo{};
		bufferInfo.sType = VK_STRUCTURE_TYPE_BUFFER_CREATE_INFO;
		bufferInfo.size = size;
		/*
		The second field is usage, which indicates for which purposes the data in the
		buffer is going to be used. It is possible to specify multiple purposes using a
		bitwise or.
		*/
		bufferInfo.usage = usage;
		/*
		Just like the images in the swap chain, buffers can also be owned by a specific
		queue family or be shared between multiple at the same time. The buffer will
		only be used from the graphics queue, so we can stick to exclusive access.
		*/
		bufferInfo.sharingMode = VK_SHARING_MODE_EXCLUSIVE;

		if (vkCreateBuffer(device, &bufferInfo, nullptr, &buffer) != VK_SUCCESS)
		{
			throw std::runtime_error("failed to create buffer!");
		}

		/*
		The buffer has been created, but it doesn’t actually have any memory assigned to
		it yet. The first step of allocating memory for the buffer is to query its memory
		requirements.
		The VkMemoryRequirements struct has three fields:
		• size: The size of the required amount of memory in bytes, may differ
		from bufferInfo.size.
		• alignment: The offset in bytes where the buffer begins in the allocated region
		of memory, depends on bufferInfo.usage and bufferInfo.flags.
		• memoryTypeBits: Bit field of the memory types that are suitable for the
		buffer.
		Graphics cards
		*/
		VkMemoryRequirements memRequirements;
		vkGetBufferMemoryRequirements(device, buffer, &memRequirements);

		/*
		In a real world application, you’re not supposed
		to actually call vkAllocateMemory for every individual buffer. The
		maximum number of simultaneous memory allocations is limited by the
		maxMemoryAllocationCount physical device limit, which may be as low as
		4096 even on high end hardware like an NVIDIA GTX 1080. The right way to
		allocate memory for a large number of objects at the same time is to create a
		custom allocator that splits up a single allocation among many different objects
		by using the offset parameters that we’ve seen in many functions.
		You can either implement such an allocator yourself, or use the VulkanMemoryAllocator
		library provided by the GPUOpen initiative. However, for this
		tutorial it’s okay to use a separate allocation for every resource, because we
		won’t come close to hitting any of these limits for now.
		*/
		VkMemoryAllocateInfo allocInfo{};
		allocInfo.sType = VK_STRUCTURE_TYPE_MEMORY_ALLOCATE_INFO;
		allocInfo.allocationSize = memRequirements.size;
		allocInfo.memoryTypeIndex = findMemoryType(memRequirements.memoryTypeBits, properties);

		if (vkAllocateMemory(device, &allocInfo, nullptr, &bufferMemory) != VK_SUCCESS)
		{
			throw std::runtime_error("failed to allocated vertex buffer memory!");
		}
		//Since this memory is allocated specifically for this the vertex buffer, the offset is simply 0.
		// If the offset is non - zero, then it is required to be divisible by memRequirements.alignment.
		vkBindBufferMemory(device, buffer, bufferMemory, 0);
	}

	uint32_t findMemoryType(uint32_t typeFilter, VkMemoryPropertyFlags properties)
	{
		VkPhysicalDeviceMemoryProperties memProperties;
		vkGetPhysicalDeviceMemoryProperties(physicalDevice, &memProperties);
		/*
		The VkPhysicalDeviceMemoryProperties structure has two arrays
		memoryTypes and memoryHeaps. Memory heaps are distinct memory resources
		like dedicated VRAM and swap space in RAM for when VRAM runs
		out. The different types of memory exist within these heaps. Right now we’ll
		only concern ourselves with the type of memory and not the heap it comes
		from, but you can imagine that this can affect performance.
		*/
		for (uint32_t i{ 0 }; i < memProperties.memoryTypeCount; i++)
		{
			/*
			The typeFilter parameter will be used to specify the bit field of memory types
			that are suitable. That means that we can find the index of a suitable memory
			type by simply iterating over them and checking if the corresponding bit is set
			to 1.
			However, we’re not just interested in a memory type that is suitable for the
			vertex buffer. We also need to be able to write our vertex data to that memory.
			The memoryTypes array consists of VkMemoryType structs that specify the heap
			and properties of each type of memory. The properties define special features
			of the memory, like being able to map it so we can write to it from the CPU.
			This property is indicated with VK_MEMORY_PROPERTY_HOST_VISIBLE_BIT, but
			we also need to use the VK_MEMORY_PROPERTY_HOST_COHERENT_BIT property.
			*/
			if (typeFilter & (1 << i) &&
				(memProperties.memoryTypes[i].propertyFlags & properties) == properties)
			{
				return i;
			}
		}
		throw std::runtime_error("failed to find suitable memory type!");
	}

	void copyBuffer(VkBuffer srcBuffer, VkBuffer dstBuffer, VkDeviceSize size)
	{
		VkCommandBuffer commandBuffer{ beginSingleTimeCommands() };

		VkBufferCopy copyRegion{};
		copyRegion.srcOffset = 0;
		copyRegion.dstOffset = 0;
		copyRegion.size = size;
		vkCmdCopyBuffer(commandBuffer, srcBuffer, dstBuffer, 1, &copyRegion);
		endSingleTimeCommands(commandBuffer);
	}

	VkCommandBuffer beginSingleTimeCommands()
	{
		VkCommandBufferAllocateInfo allocInfo{};
		allocInfo.sType = VK_STRUCTURE_TYPE_COMMAND_BUFFER_ALLOCATE_INFO;
		allocInfo.level = VK_COMMAND_BUFFER_LEVEL_PRIMARY;
		allocInfo.commandPool = commandPool;
		allocInfo.commandBufferCount = 1;

		VkCommandBuffer commandBuffer;
		vkAllocateCommandBuffers(device, &allocInfo, &commandBuffer);

		VkCommandBufferBeginInfo beginInfo{};
		beginInfo.sType = VK_STRUCTURE_TYPE_COMMAND_BUFFER_BEGIN_INFO;
		/*
		We’re only going to use the command buffer once and wait with returning
		from the function until the copy operation has finished executing.
		It’s good practice to tell the driver about our intent using
		VK_COMMAND_BUFFER_USAGE_ONE_TIME_SUBMIT_BIT.
		*/
		beginInfo.flags = VK_COMMAND_BUFFER_USAGE_ONE_TIME_SUBMIT_BIT;

		vkBeginCommandBuffer(commandBuffer, &beginInfo);
		return commandBuffer;
	}

	void endSingleTimeCommands(VkCommandBuffer commandBuffer)
	{
		vkEndCommandBuffer(commandBuffer);
		VkSubmitInfo submitInfo{};
		submitInfo.sType = VK_STRUCTURE_TYPE_SUBMIT_INFO;
		submitInfo.commandBufferCount = 1;
		submitInfo.pCommandBuffers = &commandBuffer;
		/*
		The buffer copy command requires a queue family that supports transfer operations,
		which is indicated using VK_QUEUE_TRANSFER_BIT. The good news is that
		any queue family with VK_QUEUE_GRAPHICS_BIT or VK_QUEUE_COMPUTE_BIT capabilities
		already implicitly support VK_QUEUE_TRANSFER_BIT operations. The
		implementation is not required to explicitly list it in queueFlags in those cases.
		*/
		vkQueueSubmit(graphicsQueue, 1, &submitInfo, VK_NULL_HANDLE);
		/*
		Unlike the draw commands, there are no events we need to wait on this time.
		We just want to execute the transfer on the buffers immediately. There are
		again two possible ways to wait on this transfer to complete. We could use a
		fence and wait with vkWaitForFences, or simply wait for the transfer queue
		to become idle with vkQueueWaitIdle. A fence would allow you to schedule
		multiple transfers simultaneously and wait for all of them complete, instead
		of executing one at a time. That may give the driver more opportunities to
		optimize.
		*/
		vkQueueWaitIdle(graphicsQueue);
		vkFreeCommandBuffers(device, commandPool, 1, &commandBuffer);
	}

	void createIndexBuffer()
	{
		VkDeviceSize bufferSize{ sizeof(indices[0]) * indices.size() };

		VkBuffer stagingBuffer;
		VkDeviceMemory stagingBufferMemory;

		createBuffer(bufferSize, VK_BUFFER_USAGE_TRANSFER_SRC_BIT,
			VK_MEMORY_PROPERTY_HOST_VISIBLE_BIT | VK_MEMORY_PROPERTY_HOST_COHERENT_BIT,
			stagingBuffer, stagingBufferMemory);

		void* data;
		vkMapMemory(device, stagingBufferMemory, 0, bufferSize, 0, &data);

		memcpy(data, indices.data(), (size_t)bufferSize);
		vkUnmapMemory(device, stagingBufferMemory);

		createBuffer(bufferSize, VK_BUFFER_USAGE_TRANSFER_DST_BIT | VK_BUFFER_USAGE_INDEX_BUFFER_BIT,
			VK_MEMORY_PROPERTY_DEVICE_LOCAL_BIT,
			indexBuffer, indexBufferMemory);

		copyBuffer(stagingBuffer, indexBuffer, bufferSize);

		vkDestroyBuffer(device, stagingBuffer, nullptr);
		vkFreeMemory(device, stagingBufferMemory, nullptr);
	}

	void createUniformBuffers()
	{
		VkDeviceSize bufferSize{ sizeof(UniformBufferObject) };
		uniformBuffers.resize(MAX_FRAMES_IN_FLIGHT);
		uniformBuffersMemory.resize(MAX_FRAMES_IN_FLIGHT);
		uniformBuffersMapped.resize(MAX_FRAMES_IN_FLIGHT);

		for (size_t i{ 0 }; i < MAX_FRAMES_IN_FLIGHT; i++)
		{
			createBuffer(bufferSize, VK_BUFFER_USAGE_UNIFORM_BUFFER_BIT,
				VK_MEMORY_PROPERTY_HOST_VISIBLE_BIT | VK_MEMORY_PROPERTY_HOST_COHERENT_BIT,
				uniformBuffers[i], uniformBuffersMemory[i]);
			/*
			We map the buffer right after creation using vkMapMemory to get a pointer
			to which we can write the data later on. The buffer stays mapped to this
			pointer for the application’s whole lifetime. This technique is called “persistent
			mapping” and works on all Vulkan implementations. Not having to map the
			buffer every time we need to update it increases performances, as mapping is
			not free.
			*/
			vkMapMemory(device, uniformBuffersMemory[i], 0, bufferSize, 0, &uniformBuffersMapped[i]);
		}
	}

	void createDescriptorPool()
	{
		std::array< VkDescriptorPoolSize, 2> poolSizes{};
		poolSizes[0].type = VK_DESCRIPTOR_TYPE_UNIFORM_BUFFER;
		poolSizes[0].descriptorCount = MAX_FRAMES_IN_FLIGHT;
		poolSizes[1].type = VK_DESCRIPTOR_TYPE_COMBINED_IMAGE_SAMPLER;
		poolSizes[1].descriptorCount = MAX_FRAMES_IN_FLIGHT;

		VkDescriptorPoolCreateInfo poolInfo{};
		poolInfo.sType = VK_STRUCTURE_TYPE_DESCRIPTOR_POOL_CREATE_INFO;
		poolInfo.poolSizeCount = 1;
		poolInfo.pPoolSizes = poolSizes.data();
		/*
		Aside from the maximum number of individual descriptors that are available,
		we also need to specify the maximum number of descriptor sets that may be
		allocated:
		*/
		poolInfo.maxSets = MAX_FRAMES_IN_FLIGHT;
		/*
		The structure has an optional flag similar to command pools that determines if
		individual descriptor sets can be freed or not: VK_DESCRIPTOR_POOL_CREATE_FREE_DESCRIPTOR_SET_BIT.
		We’re not going to touch the descriptor set after creating it, so we don’t need
		this flag. You can leave flags to its default value of 0.
		*/
		poolInfo.flags = 0;

		if (vkCreateDescriptorPool(device, &poolInfo, nullptr, &descriptorPool) != VK_SUCCESS)
		{
			throw std::runtime_error("failed to create descriptor pool");
		}	
	}

	void createDescriptorSets()
	{
		//In our case we will create one descriptor set for each frame in flight, all with the same layout.
		std::vector<VkDescriptorSetLayout> layouts(MAX_FRAMES_IN_FLIGHT, descriptorSetLayout);
		/*
		A descriptor set allocation is described with a VkDescriptorSetAllocateInfo
		struct. You need to specify the descriptor pool to allocate from, the number of
		descriptor sets to allocate, and the descriptor layout to base them on
		*/
		VkDescriptorSetAllocateInfo allocInfo{};
		allocInfo.sType = VK_STRUCTURE_TYPE_DESCRIPTOR_SET_ALLOCATE_INFO;
		allocInfo.descriptorPool = descriptorPool;
		allocInfo.descriptorSetCount = MAX_FRAMES_IN_FLIGHT;
		allocInfo.pSetLayouts = layouts.data();

		descriptorSets.resize(MAX_FRAMES_IN_FLIGHT);
		if (vkAllocateDescriptorSets(device, &allocInfo, descriptorSets.data()) != VK_SUCCESS)
		{
			throw std::runtime_error("failed to create descriptor sets!");
		}
		/*
		You don’t need to explicitly clean up descriptor sets, because they will
		be automatically freed when the descriptor pool is destroyed. The call
		to vkAllocateDescriptorSets will allocate descriptor sets, each with one
		uniform buffer descriptor
		*/

		for (size_t i{0}; i < MAX_FRAMES_IN_FLIGHT; i++)
		{
			/*
			Descriptors that refer to buffers, like our uniform buffer descriptor, are configured
			with a VkDescriptorBufferInfo struct. This structure specifies the buffer
			and the region within it that contains the data for the descriptor.
			*/
			VkDescriptorBufferInfo bufferInfo{};
			bufferInfo.buffer = uniformBuffers[i];
			bufferInfo.offset = 0;
			/*
			If you’re overwriting the whole buffer, like we are in this case, then it is also
			possible to use the VK_WHOLE_SIZE value for the range.
			*/
			bufferInfo.range = sizeof(UniformBufferObject);

			VkDescriptorImageInfo imageInfo{};
			imageInfo.imageLayout = VK_IMAGE_LAYOUT_SHADER_READ_ONLY_OPTIMAL;
			imageInfo.imageView = textureImageView;
			imageInfo.sampler = textureSampler;

			/*
			The configuration of descriptors
			is updated using the vkUpdateDescriptorSets function, which takes
			an array of VkWriteDescriptorSet structs as parameter.
			*/
			std::array<VkWriteDescriptorSet, 2> descriptorWrites{};
			descriptorWrites[0].sType = VK_STRUCTURE_TYPE_WRITE_DESCRIPTOR_SET;
			/*
			We gave our uniform buffer binding index 0. Remember that descriptors can be
			arrays, so we also need to specify the first index in the array that we want to
			update. We’re not using an array, so the index is simply 0.
			*/
			descriptorWrites[0].dstSet = descriptorSets[i];
			descriptorWrites[0].dstBinding = 0;
			descriptorWrites[0].dstArrayElement = 0;

			descriptorWrites[0].descriptorType = VK_DESCRIPTOR_TYPE_UNIFORM_BUFFER;
			descriptorWrites[0].descriptorCount = 1;
			/*
			The last field references an array with descriptorCount structs that actually
			configure the descriptors. It depends on the type of descriptor which one of the
			three you actually need to use. The pBufferInfo field is used for descriptors
			that refer to buffer data, pImageInfo is used for descriptors that refer to image
			data, and pTexelBufferView is used for descriptors that refer to buffer views.
			Our descriptor is based on buffers, so we’re using pBufferInfo.
			*/
			descriptorWrites[0].pBufferInfo = &bufferInfo;

			descriptorWrites[1].sType = VK_STRUCTURE_TYPE_WRITE_DESCRIPTOR_SET;
			descriptorWrites[1].dstSet = descriptorSets[i];
			descriptorWrites[1].dstBinding = 1;
			descriptorWrites[1].dstArrayElement = 0;
			descriptorWrites[1].descriptorType = VK_DESCRIPTOR_TYPE_COMBINED_IMAGE_SAMPLER;
			descriptorWrites[1].descriptorCount = 1;
			descriptorWrites[1].pImageInfo = &imageInfo;

			/*
			The updates are applied using vkUpdateDescriptorSets. It accepts two kinds
			of arrays as parameters: an array of VkWriteDescriptorSet and an array of
			VkCopyDescriptorSet. The latter can be used to copy descriptors to each other,
			as its name implies.
			*/
			vkUpdateDescriptorSets(device, descriptorWrites.size(), descriptorWrites.data(), 0, nullptr);
		}
	}

	void createCommandBuffers()
	{
		commandBuffers.resize(MAX_FRAMES_IN_FLIGHT);
		VkCommandBufferAllocateInfo allocInfo{};
		allocInfo.sType = VK_STRUCTURE_TYPE_COMMAND_BUFFER_ALLOCATE_INFO;
		allocInfo.commandPool = commandPool;
		/*
		The level parameter specifies if the allocated command buffers are primary or
		secondary command buffers.
		• VK_COMMAND_BUFFER_LEVEL_PRIMARY: Can be submitted to a queue for
		execution, but cannot be called from other command buffers.
		• VK_COMMAND_BUFFER_LEVEL_SECONDARY: Cannot be submitted directly,
		but can be called from primary command buffers. Is helpful to reuse
		common operations from primary command buffers.
		*/
		allocInfo.level = VK_COMMAND_BUFFER_LEVEL_PRIMARY;
		allocInfo.commandBufferCount = (uint32_t) commandBuffers.size();

		if (vkAllocateCommandBuffers(device, &allocInfo, commandBuffers.data()) != VK_SUCCESS)
		{
			throw std::runtime_error("failed to create command buffer!");
		}
	}

	void createSyncObjects()
	{
		imageAvailableSemaphores.resize(MAX_FRAMES_IN_FLIGHT);
		renderFinishedSemaphores.resize(MAX_FRAMES_IN_FLIGHT);
		inFlightFences.resize(MAX_FRAMES_IN_FLIGHT);
		VkSemaphoreCreateInfo semaphoreInfo{};
		semaphoreInfo.sType = VK_STRUCTURE_TYPE_SEMAPHORE_CREATE_INFO;
		
		VkFenceCreateInfo fenceInfo{};
		fenceInfo.sType = VK_STRUCTURE_TYPE_FENCE_CREATE_INFO;
		// so that the draw call does not wait on the frame which doesn't exits when doing the 1st frame
		fenceInfo.flags = VK_FENCE_CREATE_SIGNALED_BIT;

		for (size_t i{ 0 }; i < MAX_FRAMES_IN_FLIGHT; i++)
		{
			if (vkCreateSemaphore(device, &semaphoreInfo, nullptr, &imageAvailableSemaphores[i]) != VK_SUCCESS ||
				vkCreateSemaphore(device, &semaphoreInfo, nullptr, &renderFinishedSemaphores[i]) != VK_SUCCESS ||
				vkCreateFence(device, &fenceInfo, nullptr, &inFlightFences[i]) != VK_SUCCESS)
			{
				throw std::runtime_error("failed to create semaphores!");
			}
		}
	}

	void recordCommandBuffer(VkCommandBuffer commandBuffer, uint32_t imageIndex)
	{
		/*
		We always begin recording a command buffer by calling vkBeginCommandBuffer
		with a small VkCommandBufferBeginInfo structure as argument that specifies
		some details about the usage of this specific command buffer.
		*/
		VkCommandBufferBeginInfo beginInfo{};
		beginInfo.sType = VK_STRUCTURE_TYPE_COMMAND_BUFFER_BEGIN_INFO;
		/*
		The flags parameter specifies how we’re going to use the command buffer. The
		following values are available:
		• VK_COMMAND_BUFFER_USAGE_ONE_TIME_SUBMIT_BIT: The command
		buffer will be rerecorded right after executing it once.
		• VK_COMMAND_BUFFER_USAGE_RENDER_PASS_CONTINUE_BIT: This is a secondary
		command buffer that will be entirely within a single render pass.
		• VK_COMMAND_BUFFER_USAGE_SIMULTANEOUS_USE_BIT: The command
		buffer can be resubmitted while it is also already pending execution.
		*/
		beginInfo.flags = 0;
		/*
		The pInheritanceInfo parameter is only relevant for secondary command
		buffers. It specifies which state to inherit from the calling primary command
		buffers.
		*/
		beginInfo.pInheritanceInfo = nullptr;

		if (vkBeginCommandBuffer(commandBuffer, &beginInfo) != VK_SUCCESS)
		{
			throw std::runtime_error("failed to begin recording command buffer!");
		}

		VkRenderPassBeginInfo renderPassInfo{};
		renderPassInfo.sType = VK_STRUCTURE_TYPE_RENDER_PASS_BEGIN_INFO;
		/*
		The first parameters are the render pass itself and the attachments to bind. We
		created a framebuffer for each swap chain image where it is specified as a color
		attachment. Thus we need to bind the framebuffer for the swapchain image we
		want to draw to. Using the imageIndex parameter which was passed in, we can
		pick the right framebuffer for the current swapchain image.
		*/
		renderPassInfo.renderPass = renderPass;
		renderPassInfo.framebuffer = swapChainFramebuffers[imageIndex];
		renderPassInfo.renderArea.offset = { 0, 0 };
		renderPassInfo.renderArea.extent = swapChainExtent;
		/*
		The last two parameters define the clear values to use for VK_ATTACHMENT_LOAD_OP_CLEAR,
		which we used as load operation for the color attachment.
		VkClearValue clearColor = {{{0.0f, 0.0f, 0.0f, 1.0f}}};
		renderPassInfo.clearValueCount = 1;
		renderPassInfo.pClearValues = &clearColor;
		*/
		/*
		Because we now have multiple attachments with VK_ATTACHMENT_LOAD_OP_CLEAR,
		we also need to specify multiple clear values.
		The range of depths in the depth buffer is 0.0 to 1.0 in Vulkan, where 1.0 lies
		at the far view plane and 0.0 at the near view plane. The initial value at each
		point in the depth buffer should be the furthest possible depth, which is 1.0.
		Note that the order of clearValues should be identical to the order of your
		attachments.
		*/
		std::array<VkClearValue, 2> clearValues{};
		clearValues[0].color = {{0.0f, 0.0f, 0.0f, 1.0f}};
		clearValues[1].depthStencil = { 1.0f, 0 };
		renderPassInfo.clearValueCount = clearValues.size();
		renderPassInfo.pClearValues = clearValues.data();

		/*
		The final parameter controls how the drawing commands
		within the render pass will be provided. It can have one of two values:
		• VK_SUBPASS_CONTENTS_INLINE: The render pass commands will be embedded
		in the primary command buffer itself and no secondary command
		buffers will be executed.
		• VK_SUBPASS_CONTENTS_SECONDARY_COMMAND_BUFFERS: The render pass
		commands will be executed from secondary command buffers.
		*/
		vkCmdBeginRenderPass(commandBuffer, &renderPassInfo, VK_SUBPASS_CONTENTS_INLINE);
		//The second parameter specifies if the pipeline object is a graphics or compute pipeline.
		vkCmdBindPipeline(commandBuffer, VK_PIPELINE_BIND_POINT_GRAPHICS, graphicsPipeline);

		VkBuffer vertexBuffers[] = { vertexBuffer };
		VkDeviceSize offsets[] = { 0 };
		vkCmdBindVertexBuffers(commandBuffer, 0, 1, vertexBuffers, offsets);
		/*
		You can only have a single index buffer. It’s unfortunately
		not possible to use different indices for each vertex attribute, so we do still
		have to completely duplicate vertex data even if just one attribute varies.
		*/
		vkCmdBindIndexBuffer(commandBuffer, indexBuffer, 0, VK_INDEX_TYPE_UINT16);

		/*
		we did specify viewport and scissor
		state for this pipeline to be dynamic. So we need to set them in the command
		buffer before issuing our draw command:
		*/
		VkViewport viewport{};
		viewport.x = 0.0f;
		viewport.y = 0.0f;
		viewport.width = swapChainExtent.width;
		viewport.height = swapChainExtent.height;
		viewport.minDepth = 0.0f;
		viewport.maxDepth = 1.0f;
		vkCmdSetViewport(commandBuffer, 0, 1, &viewport);

		VkRect2D scissor{};
		scissor.offset = { 0, 0 };
		scissor.extent = swapChainExtent;
		vkCmdSetScissor(commandBuffer, 0, 1, &scissor);

		/*
		bind the right descriptor set for each frame to the descriptors in the
		shader with vkCmdBindDescriptorSets. This needs to be done before the
		vkCmdDrawIndexed call

		Unlike vertex and index buffers, descriptor sets are not unique to graphics
		pipelines. Therefore we need to specify if we want to bind descriptor sets to
		the graphics or compute pipeline. The next parameter is the layout that the
		descriptors are based on. The next three parameters specify the index of the
		first descriptor set, the number of sets to bind, and the array of sets to bind.
		The last two parameters specify an array
		of offsets that are used for dynamic descriptors. We’ll look at these in a future
		chapter.
		*/
		vkCmdBindDescriptorSets(commandBuffer, VK_PIPELINE_BIND_POINT_GRAPHICS, pipelineLayout,
			0, 1, &descriptorSets[currentFrame], 0, nullptr);
		/*
		The first two parameters
		specify the number of indices and the number of instances. We’re not using
		instancing, so just specify 1 instance. The number of indices represents the
		number of vertices that will be passed to the vertex shader. The next parameter
		specifies an offset into the index buffer, using a value of 1 would cause the
		graphics card to start reading at the second index. The second to last parameter
		specifies an offset to add to the indices in the index buffer. The final parameter
		specifies an offset for instancing, which we’re not using.
		*/
		vkCmdDrawIndexed(commandBuffer, indices.size(), 1, 0, 0, 0);

		vkCmdEndRenderPass(commandBuffer);

		if (vkEndCommandBuffer(commandBuffer) != VK_SUCCESS)
		{
			throw std::runtime_error("failed to record command buffer!");
		}
	}

	/*
	At a high level, rendering a frame in Vulkan consists of a common set of steps:
	• Wait for the previous frame to finish
	• Acquire an image from the swap chain
	• Record a command buffer which draws the scene onto that image
	• Submit the recorded command buffer
	• Present the swap chain image
	*/
	void drawFrame()
	{
		/*
		At the start of the frame, we want to wait until the previous frame has finished,
		so that the command buffer and semaphores are available to use.
		The VK_TRUE we pass here indicates that we want to wait for all fences, but in the case of a
		single one it doesn’t matter. This function also has a timeout parameter that
		we set to the maximum value of a 64 bit unsigned integer, UINT64_MAX, which
		effectively disables the timeout.
		*/
		vkWaitForFences(device, 1, &inFlightFences[currentFrame], VK_TRUE, UINT64_MAX);

		uint32_t imageIndex;
		/*
		The last parameter specifies a variable to output the index of the swap
		chain image that has become available. The index refers to the VkImage
		in our swapChainImages array. We’re going to use that index to pick the
		VkFrameBuffer
		*/
		VkResult result{ 
			vkAcquireNextImageKHR(device, swapChain, UINT32_MAX, imageAvailableSemaphores[currentFrame],
				VK_NULL_HANDLE, &imageIndex)
		};

		/*
		The vkAcquireNextImageKHR and vkQueuePresentKHR functions can return the following
		special values.
		• VK_ERROR_OUT_OF_DATE_KHR: The swap chain has become incompatible
		with the surface and can no longer be used for rendering. Usually happens
		after a window resize.
		• VK_SUBOPTIMAL_KHR: The swap chain can still be used to successfully
		present to the surface, but the surface properties are no longer matched
		exactly.
		*/
		if (result == VK_ERROR_OUT_OF_DATE_KHR)
		{
			recreateSwapChain();
			return;
		}
		else if (result != VK_SUCCESS && result != VK_SUBOPTIMAL_KHR)
		{
			throw std::runtime_error("failed to acquire swap chain image!");
		}
		// Only reset the fence if we are submitting work
		vkResetFences(device, 1, &inFlightFences[currentFrame]);

		vkResetCommandBuffer(commandBuffers[currentFrame], 0);
		recordCommandBuffer(commandBuffers[currentFrame], imageIndex);

		//This function will generate a new transformation every frame to make the geometry spin around.
		updateUniformBuffer(currentFrame);

		VkSubmitInfo submitInfo{};
		submitInfo.sType = VK_STRUCTURE_TYPE_SUBMIT_INFO;

		/*
		The first three parameters specify which semaphores to wait on before execution
		begins and in which stage(s) of the pipeline to wait. We want to wait with
		writing colors to the image until it’s available, so we’re specifying the stage of
		the graphics pipeline that writes to the color attachment. That means that
		theoretically the implementation can already start executing our vertex shader
		and such while the image is not yet available. Each entry in the waitStages
		array corresponds to the semaphore with the same index in pWaitSemaphores.
		*/
		VkSemaphore waitSemaphores[] = { imageAvailableSemaphores[currentFrame]};
		VkPipelineStageFlags waitStages[] = { VK_PIPELINE_STAGE_COLOR_ATTACHMENT_OUTPUT_BIT };
		submitInfo.waitSemaphoreCount = 1;
		submitInfo.pWaitSemaphores = waitSemaphores;
		submitInfo.pWaitDstStageMask = waitStages;

		submitInfo.commandBufferCount = 1;
		submitInfo.pCommandBuffers = &commandBuffers[currentFrame];

		/*
		The signalSemaphoreCount and pSignalSemaphores parameters specify which
		semaphores to signal once the command buffer(s) have finished execution. In
		our case we’re using the renderFinishedSemaphore for that purpose.
		*/
		VkSemaphore signalSemaphores[] = { renderFinishedSemaphores[currentFrame]};
		submitInfo.signalSemaphoreCount = 1;
		submitInfo.pSignalSemaphores = signalSemaphores;

		if (vkQueueSubmit(graphicsQueue, 1, &submitInfo, inFlightFences[currentFrame]) != VK_SUCCESS)
		{
			throw std::runtime_error("failed to submit draw command buffer!");
		}

		VkPresentInfoKHR presentInfo{};
		presentInfo.sType = VK_STRUCTURE_TYPE_PRESENT_INFO_KHR;
		/*
		The first two parameters specify which semaphores to wait on before presentation
		can happen, just like VkSubmitInfo. Since we want to wait on the command
		buffer to finish execution, thus our triangle being drawn, we take the semaphores
		which will be signalled and wait on them, thus we use signalSemaphores.
		*/
		presentInfo.waitSemaphoreCount = 1;
		presentInfo.pWaitSemaphores = signalSemaphores;

		/*
		The next two parameters specify the swap chains to present images to and the
		index of the image for each swap chain. This will almost always be a single one.
		*/
		VkSwapchainKHR swapChains[] = { swapChain };
		presentInfo.swapchainCount = 1;
		presentInfo.pSwapchains = swapChains;
		presentInfo.pImageIndices = &imageIndex;
		/*
		There is one last optional parameter called pResults. It allows you to specify
		an array of VkResult values to check for every individual swap chain if presentation
		was successful. It’s not necessary if you’re only using a single swap chain,
		because you can simply use the return value of the present function.
		*/
		presentInfo.pResults = nullptr;

		//The vkQueuePresentKHR function submits the request to present an image to the swap chain.
		result = vkQueuePresentKHR(presentQueue, &presentInfo);

		if (result == VK_ERROR_OUT_OF_DATE_KHR || result == VK_SUBOPTIMAL_KHR || framebufferResized)
		{
			framebufferResized = false;
			recreateSwapChain();
		}
		else if (result != VK_SUCCESS)
		{
			throw std::runtime_error("failed to present swap chain image!");
		}

		//By using the modulo (%) operator, we ensure that the frame index loops around
		//after every MAX_FRAMES_IN_FLIGHT enqueued frames.
		currentFrame = (currentFrame + 1) % MAX_FRAMES_IN_FLIGHT;
	}

	void recreateSwapChain()
	{
		int width{ 0 };
		int height{ 0 };
		glfwGetFramebufferSize(window, &width, &height);
		while (width == 0 || height == 0)
		{
			glfwGetFramebufferSize(window, &width, &height);
			glfwWaitEvents();
		}
		/*
		We first call vkDeviceWaitIdle, because we
		shouldn’t touch resources that may still be in use. Obviously, we’ll have to
		recreate the swap chain itself. The image views need to be recreated because
		they are based directly on the swap chain images. Finally, the framebuffers
		directly depend on the swap chain images, and thus must be recreated as well.
		*/
		vkDeviceWaitIdle(device);

		cleanupSwapChain();

		createSwapChain();
		createImageViews();
		createDepthResources();
		createFramebuffers();
	}

	void updateUniformBuffer(uint32_t currentImage)
	{
		/*
		The updateUniformBuffer function will start out with some logic to calculate
		the time in seconds since rendering has started with floating point accuracy.
		*/
		static auto startTime{ std::chrono::high_resolution_clock::now() };
		auto currentTime{ std::chrono::high_resolution_clock::now() };
		float time{ std::chrono::duration<float, std::chrono::seconds::period>(currentTime - startTime).count() };

		/*
		We will now define the model, view and projection transformations in the uniform
		buffer object. The model rotation will be a simple rotation around the
		Z-axis using the time variable:
		*/
		UniformBufferObject ubo{};
		/*
		The glm::rotate function takes an existing transformation, rotation angle and
		rotation axis as parameters. The glm::mat4(1.0f) constructor returns an identity
		matrix. Using a rotation angle of time * glm::radians(90.0f) accomplishes
		the purpose of rotation 90 degrees per second.
		*/
		ubo.model = glm::rotate(glm::mat4(1.0f), time * glm::radians(90.0f), glm::vec3(0.0f, 0.0f, 1.0f));
		/*
		For the view transformation we look at the geometry from above
		at a 45 degree angle. The glm::lookAt function takes the eye position, center
		position and up axis as parameters.
		*/
		ubo.view = glm::lookAt(glm::vec3(2.0f, 2.0f, 2.0f), glm::vec3(0.0f, 0.0f, 0.0f), glm::vec3(0.0f, 0.0f, 1.0f));
		/*
		perspective projection with a 45 degree vertical field-ofview.
		The other parameters are the aspect ratio, near and far view planes. It
		is important to use the current swap chain extent to calculate the aspect ratio
		to take into account the new width and height of the window after a resize.
		*/
		ubo.proj = glm::perspective(glm::radians(45.0f), swapChainExtent.width / (float)swapChainExtent.height, 0.1f, 10.0f);
		/*
		GLM was originally designed for OpenGL, where the Y coordinate of the clip
		coordinates is inverted. The easiest way to compensate for that is to flip the
		sign on the scaling factor of the Y axis in the projection matrix. If you don’t
		do this, then the image will be rendered upside down.
		*/
		ubo.proj[1][1] *= -1;
		/*
		All of the transformations are defined now, so we can copy the data in the
		uniform buffer object to the current uniform buffer. This happens in exactly
		the same way as we did for vertex buffers, except without a staging buffer. As
		noted earlier, we only map the uniform buffer once, so we can directly write to
		it without having to map again:
		*/
		memcpy(uniformBuffersMapped[currentImage], &ubo, sizeof(ubo));
	}

	/*
		The first parameter specifies the severity of the message, which is one of the
		following flags:
		• VK_DEBUG_UTILS_MESSAGE_SEVERITY_VERBOSE_BIT_EXT: Diagnostic
		message
		• VK_DEBUG_UTILS_MESSAGE_SEVERITY_INFO_BIT_EXT: Informational message
		like the creation of a resource
		• VK_DEBUG_UTILS_MESSAGE_SEVERITY_WARNING_BIT_EXT: Message about
		behavior that is not necessarily an error, but very likely a bug in your
		application
		• VK_DEBUG_UTILS_MESSAGE_SEVERITY_ERROR_BIT_EXT: Message about
		behavior that is invalid and may cause crashes

		The messageType parameter can have the following values:
		• VK_DEBUG_UTILS_MESSAGE_TYPE_GENERAL_BIT_EXT: Some event has happened
		that is unrelated to the specification or performance
		• VK_DEBUG_UTILS_MESSAGE_TYPE_VALIDATION_BIT_EXT: Something has
		happened that violates the specification or indicates a possible mistake
		• VK_DEBUG_UTILS_MESSAGE_TYPE_PERFORMANCE_BIT_EXT: Potential nonoptimal
		use of Vulkan

		The pCallbackData parameter refers to a VkDebugUtilsMessengerCallbackDataEXT
		struct containing the details of the message itself, with the most important
		members being:
		• pMessage: The debug message as a null-terminated string
		• pObjects: Array of Vulkan object handles related to the message
		• objectCount: Number of objects in array

		The pUserData parameter contains a pointer that was specified during
		the setup of the callback and allows you to pass your own data to it.
		The callback returns a boolean that indicates if the Vulkan call that triggered
		the validation layer message should be aborted. If the callback returns true, then
		the call is aborted with the VK_ERROR_VALIDATION_FAILED_EXT error. This is
		normally only used to test the validation layers themselves, so you should always
		return VK_FALSE.

	*/
	//[storage-class specifier] [return type and attributes] [calling convention] functionName(parameters)
	/*
	static        VKAPI_ATTR         VkBool32           VKAPI_CALL   debugCallback(...)
	^ storage	  ^ attribute macro  ^ return type      ^ call conv  ^ function name

	static __declspec(dllexport) VkBool32 __stdcall debugCallback(...)

		__declspec(dllexport): make it visible to the dynamic loader (if needed)

		VkBool32: return a 32-bit int boolean

		__stdcall: use the correct calling convention for the Vulkan runtime to call it
	*/
	static VKAPI_ATTR VkBool32 VKAPI_CALL debugCallback(
		VkDebugUtilsMessageSeverityFlagBitsEXT messageSeverity,
		VkDebugUtilsMessageTypeFlagsEXT messageType,
		const VkDebugUtilsMessengerCallbackDataEXT* pCallbackData,
		void* pUserData
	)
	{
		std::cerr << "validation layer: " << pCallbackData->pMessage << std::endl;
		return VK_FALSE;
	}

	static std::vector<char> readFile(const std::string& filename)
	{
		/*
		• ate: Start reading at the end of the file
		• binary: Read the file as binary file (avoid text transformations)
		The advantage of starting to read at the end of the file is that we can use the
		read position to determine the size of the file and allocate a buffer:
		*/
		std::ifstream file{ filename, std::ios::ate | std::ios::binary };
		if (!file.is_open())
		{
			throw std::runtime_error("failed to open file!");
		}
		size_t fileSize{ (size_t)file.tellg() };
		std::vector<char> buffer(fileSize);
		//seek back to the beginning of the file and read all of the bytes at once
		file.seekg(0);
		file.read(buffer.data(), fileSize);
		file.close();
		return buffer;
	}

	static void framebufferResizeCallback(GLFWwindow* window, int width, int height)
	{
		auto app{ reinterpret_cast<HelloTriangleApplication*>(glfwGetWindowUserPointer(window)) };
		app->framebufferResized = true;
	}
};

int main()
{
	HelloTriangleApplication app;

	try {
		app.run();
	}
	catch (const std::exception& e)
	{
		std::cerr << e.what() << std::endl;
		return EXIT_FAILURE;
	}

	return EXIT_SUCCESS;
}